{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Document Classification\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 06.11.2015\n",
    "\n",
    "[Übersicht Versuche im Data Mining Praktikum](http://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "## Abgabe:\n",
    "\n",
    "- **Abzugeben ist das Jupyter Notebook mit dem verlangten Implementierungen und den entsprechenden Ausgaben.**\n",
    "- **Das Notebook ist als .ipynb und als .html abzugeben.**\n",
    "- **Klausurelevante Fragen sind Dokument \"Fragenkatalog Datamining\" zu finden.**\n",
    "- Antworten auf Fragen im Notebook, Diskussionen und Beschreibung der Ergebnisse sind optional (aber empfohlen) und werden nicht bewertet.\n",
    "\n",
    "* [Übersicht Data Mining Praktikum](https://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "\n",
    "# Einführung\n",
    "\n",
    "## Lernziele:\n",
    "\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Dokumentklassifikation: Klassifikation von Dokumenten, insbesondere Emails und RSS Feed\n",
    "* Naive Bayes Classifier: Weit verbreitete Klassifikationsmethode, welche unter bestimmten Randbedingungen sehr gut skaliert.\n",
    "\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "\n",
    "### Parametrische Klassifikation und Naive Bayes Methode\n",
    "\n",
    "Klassifikatoren müssen zu einer gegebenen Eingabe $\\underline{x}$ die zugehörige Klasse $C_i$ bestimmen. Mithilfe der Wahrscheinlichkeitstheorie kann diese Aufgabe wie folgt beschrieben werden: Bestimme für alle möglichen Klassen $C_i$ die bedingte Wahrscheinlichkeit $P(C_i | \\underline{x})$, also die Wahrscheinlichkeit, dass die gegebene Eingabe $\\underline{x}$ in Klasse $C_i$ fällt. Wähle dann die Klasse aus, für welche diese Wahrscheinlichkeit maximal ist.\n",
    "\n",
    "Die Entscheidungsregeln von Klassifikatoren können mit Methoden des \"überwachten Lernens\" aus Trainingsdaten ermittelt werden. Im Fall des **parametrischen Lernens** kann aus den Trainingsdaten die sogenannte **Likelihood-Funktion** $p(\\underline{x} \\mid C_i)$ bestimmt werden. _Anmerkung:_ Allgemein werden mit $p(...)$ kontinuierliche Wahrscheinlichkeitsfunktionen und mit $P(...)$ diskrete Wahrscheinlichkeitswerte bezeichnet. \n",
    "\n",
    "Mithilfe der **Bayes-Formel**\n",
    "$$\n",
    "P(C_i \\mid \\underline{x}) = \\frac{p(\\underline{x} \\mid C_i) \\cdot P(C_i)}{p(\\underline{x})}\n",
    "$$\n",
    "\n",
    "kann aus der Likelihood die **a-posteriori-Wahrscheinlichkeit $P(C_i \\mid \\underline{x})$** berechnet werden. Darin wird $P(C_i)$ die **a-priori-Wahrscheinlichkeit** und $p(\\underline{x})$ die **Evidenz** genannt. Die a-priori-Wahrscheinlichkeit kann ebenfalls aus den Trainingsdaten ermittelt werden. Die Evidenz ist für die Klassifikationsentscheidung nicht relevant, da sie für alle Klassen $C_i$ gleich groß ist.\n",
    "\n",
    "Die Berechnung der Likelihood-Funktion $p(\\underline{x} \\mid C_i)$ ist dann sehr aufwendig, wenn $\\underline{x}=(x_1,x_2,\\ldots,x_Z)$ ein Vektor von voneinander abhängigen Variablen $x_i$ ist. Bei der **Naive Bayes Classification** wird jedoch von der vereinfachenden Annahme ausgegangen, dass die Eingabevariabeln $x_i$ voneinander unabhängig sind. Dann vereinfacht sich die bedingte Verbundwahrscheinlichkeits-Funktion $p(x_1,x_2,\\ldots,x_Z \\mid C_i)$ zu:\n",
    "\n",
    "$$\n",
    "p(x_1,x_2,\\ldots,x_Z \\mid C_i)=\\prod\\limits_{j=1}^Z p(x_j | C_i)\n",
    "$$\n",
    "\n",
    "### Anwendung der Naive Bayes Methode in der Dokumentklassifikation\n",
    "\n",
    "Auf der rechten Seite der vorigen Gleichung stehen nur noch von den jeweils anderen Variablen unabhängige bedingte Wahrscheinlichkeiten. Im Fall der Dokumentklassifikation sind die einzelnen Worte die Variablen, d.h. ein Ausdruck der Form $P(x_j | C_i)$ gibt an mit welcher Wahrscheinlichkeit ein Wort $x_j=w$ in einem Dokument der Klasse $C_i$ vorkommt. \n",
    "Die Menge aller Variablen $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ ist dann die Menge aller Wörter im Dokument. Damit gibt die linke Seite in der oben gegebenen Gleichung die *Wahrscheinlichkeit, dass die Wörter $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ in einem Dokument der Klasse $C_i$ vorkommen*, an.\n",
    "\n",
    "Für jedes Wort _w_ wird aus den Trainingsdaten die Wahrscheinlichkeit $P(w|G)$, mit der das Wort in Dokumenten der Kategorie _Good_ und die Wahrscheinlichkeit $P(w|B)$ mit der das Wort in Dokumenten der Kategorie _Bad_ auftaucht ermittelt. Trainingsdokumente werden in der Form\n",
    "\n",
    "$$\n",
    "tD=(String,Category)\n",
    "$$\n",
    "eingegeben. \n",
    "\n",
    "Wenn \n",
    "\n",
    "* mit der Variable $fc(w,cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ in denen das Wort $w$ enthalten ist\n",
    "* mit der Variable $cc(cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ \n",
    "\n",
    "gezählt wird, dann ist \n",
    "\n",
    "$$\n",
    "P(w|G)=\\frac{fc(w,G)}{cc(G)} \\quad \\quad P(w|B)=\\frac{fc(w,B)}{cc(B)}.\n",
    "$$\n",
    "\n",
    "Wird nun nach der Eingabe von $L$ Trainingsdokumenten ein neu zu klassifizierendes Dokument $D$ eingegeben und sei $W(D)$ die Menge aller Wörter in $D$, dann berechnen sich unter der Annahme, dass die Worte in $W(D)$ voneinander unabhängig sind (naive Bayes Annahme) die a-posteriori Wahrscheinlichkeiten zu:\n",
    "\n",
    "$$\n",
    "P(G|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | G) \\right) \\cdot P(G)}{p(D)}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | B) \\right) \\cdot P(B)}{p(D)}.\n",
    "$$\n",
    "\n",
    "Die hierfür notwendigen a-priori-Wahrscheinlichkeiten berechnen sich zu \n",
    "\n",
    "$$\n",
    "P(G)=\\frac{cc(G)}{L}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B)=\\frac{cc(B)}{L}\n",
    "$$\n",
    "\n",
    "Die Evidenz $p(D)$ beeinflusst die Entscheidung nicht und kann deshalb ignoriert werden.\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "\n",
    "1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training für die spätere Klassifikation abgespeichert werden?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tatsächlich gegeben?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Betrachten Sie die Formeln für die Berechnung von $P(G|D)$ und $P(B|D)$. Welches Problem stellt sich ein, wenn in der Menge $W(D)$ ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie $G$ vorkommt und ein anderes Wort aus $W(D)$ nicht in den Trainingsdaten der Kategorie $B$ enthalten ist? Wie könnte dieses Problem gelöst werden? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Feature Extraction/ -Selection\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie eine Funktion *getwords(doc)*, der ein beliebiges Dokument in Form einer String-Variablen übergeben wird. In der Funktion soll der String in seine Wörter zerlegt und jedes Wort in _lowercase_ transformiert werden. Wörter, die weniger als eine untere Grenze von Zeichen (z.B. 3) oder mehr als eine obere Grenze von Zeichen (z.B. 20) enthalten, sollen ignoriert werden. Die Funktion soll ein dictionary zurückgeben, dessen _Keys_ die Wörter sind. Die _Values_ sollen für jedes Wort zunächst auf $1$ gesetzt werden.\n",
    "\n",
    "**Tipp:** Benutzen Sie für die Zerlegung des Strings und für die Darstellung aller Wörter mit ausschließlich kleinen Buchstaben die Funktionen *split(), strip('sep')* und *lower()* der Klasse *String*.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getwords(doc):\n",
    "    doc = doc.split()\n",
    "    doc = [i.lower() for i in doc]\n",
    "    doc = [i for i in doc if len(i) >= 3 and len(i) <= 20]\n",
    "    doc = {key:1 for key in doc}\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ich': 1,\n",
       " 'bin': 1,\n",
       " 'oliver': 1,\n",
       " 'und': 1,\n",
       " 'liebe': 1,\n",
       " 'mit': 1,\n",
       " 'daten': 1,\n",
       " 'arbeiten': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Ich bin Oliver und ich liebe es mit Daten zu arbeiten\"\n",
    "\n",
    "getwords(doc=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie den Naive Bayes Classifier für die Dokumentklassifikation. Es bietet sich an die Funktionalität des Klassifikators und das vom Klassifikator gelernte Wissen in einer Instanz einer Klasse _Classifier_ zu kapseln. In diesem Fall kann wie folgt vorgegangen werden:\n",
    "\n",
    "* Im Konstruktor der Klasse wird je ein Dictionary für die Instanzvariablen _fc_ und _cc_ (siehe oben) initialisiert. Dabei ist _fc_ ein verschachteltes Dictionary. Seine Keys sind die bisher gelernten Worte, die Values sind wiederum Dictionaries, deren Keys die Kategorien _Good_ und _Bad_ sind und deren Values zählen wie häufig das Wort bisher in Dokumenten der jeweiligen Kategorie auftrat. Das Dictionary _cc_ hat als Keys die Kategorien _Good_ und _Bad_. Die Values zählen wie häufig Dokumente der jeweiligen Kategorien bisher auftraten.\n",
    "* Im Konstruktor wird ferner der Instanzvariablen _getfeatures_ die Funktion *getwords()* übergeben. Die Funktion _getwords()_ wurde bereits zuvor ausserhalb der Klasse definiert. Sinn dieses Vorgehens ist, dass andere Varianten um Merkmale aus Dokumenten zu extrahieren denkbar sind. Diese Varianten könnten dann ähnlich wie die *getwords()*-Funktion ausserhalb der Klasse definiert und beim Anlegen eines *Classifier*-Objekts der Instanzvariablen _getfeatures_ übergeben werden.  \n",
    "* Der Methode _incf(self,f,cat)_ wird ein Wort _f_ und die zugehörige Kategorie _cat_ des Dokuments in welchem es auftrat übergeben. In der Methode wird der *fc*-Zähler angepasst.\n",
    "* Der Methode _incc(self,cat)_ wird die Kategorie _cat_ des gerade eingelesenen Dokuments übergeben. In der Methode wird der *cc*-Zähler angepasst.\n",
    "* Die Methode _fcount(self,f,cat)_ gibt die Häufigkeit des Worts _f_ in den Dokumenten der Kategorie _cat_ zurück.\n",
    "* Die Methode _catcount(self,cat)_ gibt die Anzahl der Dokumente in der Kategorie _cat_ zurück.\n",
    "* Die Methode _totalcount(self)_ gibt die Anzahl aller Dokumente zurück.\n",
    "* Der Methode _train(self,item,cat)_ wird ein neues Trainingselement, bestehend aus der Betreffzeile (*item*) und der entsprechenden Kategorisierung (*cat*) übergeben. Der String _item_ wird mit der Instanzmethode _getfeatures_ (Diese referenziert *getwords()*) in Worte zerlegt. Für jedes einzelne Wort wird dann *incf(self,f,cat)* aufgerufen. Ausserdem wird für das neue Trainingsdokument die Methode _incc(self,cat)_ aufgerufen.\n",
    "* Die Methode _fprob(self,f,cat)_ berechnet die bedingte Wahrscheinlichkeit $P(f | cat)$ des Wortes _f_ in der Kategorie _cat_ entsprechend der oben angegebenen Formeln, indem sie den aktuellen Stand des Zählers _fc(f,cat)_ durch den aktuellen Stand des Zählers _cc(cat)_ teilt.   \n",
    "* Die Methode _fprob(self,f,cat)_ liefert evtl. ungewollt extreme Ergebnisse, wenn noch wenig Wörter im Klassifizierer verbucht sind. Kommt z.B. ein Wort erst einmal in den Trainingsdaten vor, so wird seine Auftrittswahrscheinlichkeit in der Kategorie in welcher es nicht vorkommt gleich 0 sein. Um extreme Wahrscheinlichkeitswerte im Fall noch selten vorkommender Werte zu vermeiden, soll zusätzlich zur Methode _fprob(self,f,cat)_ die Methode _weightedprob(self,f,cat)_ implementiert und angewandt werden. Der von ihr zurückgegebene Wahrscheinlichkeitswert könnte z.B. wie folgt berechnet werden:$$wprob=\\frac{initprob+count \\cdot fprob(self,f,cat)}{1+count},$$ wobei $initprob$ ein initialer Wahrscheinlichkeitswert (z.B. 0.5) ist, welcher zurückgegeben werden soll, wenn das Wort noch nicht in den Trainingsdaten aufgetaucht ist. Die Variable $count$ zählt wie oft das Wort $f$ bisher in den Trainingsdaten auftrat. Wie zu erkennen ist, nimmt der Einfluss der initialen Wahrscheinlichkeit ab, je häufiger das Wort in den Trainingsdaten auftrat.\n",
    "* Nach dem Training soll ein beliebiges neues Dokument (Text-String) eingegeben werden können. Für dieses soll mit der Methode _prob(self,item,cat)_ die a-posteriori-Wahrscheinlichkeit $P(cat|item)$ (Aufgrund der Vernachlässigung der Evidenz handelt es sich hierbei genaugenommen um das Produkt aus a-posteriori-Wahrscheinlichkeit und Evidenz), mit der das Dokument _item_ in die Kategorie _cat_ fällt berechnet werden. Innerhalb der Methode _prob(self,item,cat)_ soll zunächst die Methode _weightedprob(self,f,cat)_ für alle Wörter $f$ im Dokument _item_ aufgerufen werden. Die jeweiligen Rückgabewerte von _weightedprob(self,f,cat)_ werden multipliziert. Das Produkt der Rückgabewerte von _weightedprob(self,f,cat)_ über alle Wörter $f$ im Dokument muss schließlich noch mit der a-priori Wahrscheinlichkeit $P(G)$ bzw. $P(B)$ entsprechend der oben aufgeführten Formeln multipliziert werden. Das Resultat des Produkts wird an das aufrufende Programm zurück gegeben, die Evidenz wird also vernachlässigt (wie oben begründet).\n",
    "\n",
    "\n",
    "\n",
    "Ein Dokument _item_ wird schließlich der Kategorie _cat_ zugeteilt, für welche die Funktion _prob(self,item,cat)_ den höheren Wert zurück gibt. Da die Rückgabewerte in der Regel sehr klein sind, werden in der Regel folgende Werte angezeigt:\n",
    "* Wenn mit $g$ der Rückgabewert von _prob(self,item,cat=G)_ und mit $b$ der Rückgabewert von _prob(self,item,cat=B)_ bezeichnet wird dann ist die Wahrscheinlichkeit, dass $item$ in die Kategorie $G$ fällt, gleich:\n",
    "$$\n",
    "\\frac{g}{g+b}\n",
    "$$\n",
    "* und die Wahrscheinlichkeit, dass $item$ in die Kategorie $B$ fällt, gleich:\n",
    "$$\n",
    "\\frac{b}{g+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "**Aufgabe:**\n",
    "Instanzieren Sie ein Objekt der Klasse _Classifier_ und übergeben Sie der _train()_ Methode dieser Klasse mindestens 8 kategorisierte Dokumente (Betreffzeilen als Stringvariablen zusammen mit der Kategorie Good oder Bad). Definieren Sie dann ein beliebig neues Dokument und berechnen Sie für dieses die Kategorie, in welches es mit größter Wahrscheinlichkeit fällt. Benutzen Sie für den Test das in der\n",
    "[NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/07classificationNaiveBayes.html)\n",
    "ausführlich beschriebene Beispiel zu implementieren. Berechnen Sie die Klassifikatorausgabe des Satzes _the money jumps_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von RSS Newsfeeds\n",
    "Mit dem unten gegebenen Skript werden Nachrichten verschiedener Newsserver geladen und ausgegeben. Ändern Sie diese Methode ab, damit diese Strings gespeichert werden und für ein Training benutzt werden können. \n",
    "\n",
    "**Aufgaben:**\n",
    "1. Trainieren Sie Ihren Naive Bayes Classifier mit allen Nachrichten der in den Listen _trainTech_ und _trainNonTech_ definierten Servern. Weisen Sie für das Training allen Nachrichten aus _trainTech_ die Kategorie _Tech_ und allen Nachrichten aus _trainNonTech_ die Kategorie _NonTech_ zu.\n",
    "2. Nach dem Training sollen alle Nachrichten aus der Liste _test_ vom Naive Bayes Classifier automatisch klassifiziert werden. Gehen Sie davon aus, dass alle Nachrichten von [http://rss.golem.de/rss.php?r=sw&feed=RSS0.91](http://rss.golem.de/rss.php?r=sw&feed=RSS0.91) tatsächlich von der Kategorie _Tech_ sind und alle Nachrichten von den beiden anderen Servern in der Liste _test_ von der Kategorie _NonTech_ sind. Bestimmen Sie die _Konfusionsmatrix_ und die _Accuracy_ sowie für beide Klassen _Precision, Recall_ und _F1-Score_. Diese Qualitätsmetriken sind z.B. in [NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/06classificationMetrics.html) definiert.\n",
    "3. Diskutieren Sie das Ergebnis\n",
    "4. Wie könnte die Klassifikationsgüte durch Modifikation der *getwords()*-Methode verbessert werden? Implementieren Sie diesen Ansatz und vergleichen Sie das Ergebnis mit dem des ersten Ansatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "def countFeed(feedList, title, should_print=False):\n",
    "    if should_print:\n",
    "        print(f\"--------------------News from {title}------------------------\")\n",
    "    count = 0\n",
    "    for feed in feedList:\n",
    "        if should_print:\n",
    "            print()\n",
    "            print(\"*\"*30)\n",
    "            print(feed)\n",
    "        f=feedparser.parse(feed)\n",
    "        for e in f.entries:\n",
    "            if hasattr(e, 'title') and hasattr(e, 'description'):\n",
    "                if should_print:\n",
    "                    print('\\n---------------------------')\n",
    "                fulltext=stripHTML(e.title+' '+e.description)\n",
    "                if should_print:\n",
    "                    print(fulltext)\n",
    "                count += 1\n",
    "    if should_print:\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "    return count\n",
    "\n",
    "def stripHTML(h):\n",
    "    p=''\n",
    "    s=0\n",
    "    for c in h:\n",
    "        if c=='<': \n",
    "            s=1\n",
    "        elif c=='>':\n",
    "            s=0\n",
    "            p+=' '\n",
    "        elif s==0:\n",
    "            p+=c\n",
    "    return p\n",
    "\n",
    "\n",
    "trainTech=['http://rss.chip.de/c/573/f/7439/index.rss',\n",
    "           #'http://feeds.feedburner.com/netzwelt',\n",
    "           'http://rss1.t-online.de/c/11/53/06/84/11530684.xml',\n",
    "           'http://www.computerbild.de/rssfeed_2261.xml?node=13',\n",
    "           'http://www.heise.de/newsticker/heise-top-atom.xml']\n",
    "\n",
    "trainNonTech=['http://newsfeed.zeit.de/index',\n",
    "              'http://newsfeed.zeit.de/wirtschaft/index',\n",
    "              'http://www.welt.de/politik/?service=Rss',\n",
    "              'http://www.spiegel.de/schlagzeilen/tops/index.rss',\n",
    "              'https://rss.sueddeutsche.de/alles',\n",
    "              'http://www.faz.net/rss/aktuell/']\n",
    "\n",
    "test=['http://rss.golem.de/rss.php?r=sw&feed=RSS0.91',\n",
    "      'http://newsfeed.zeit.de/politik/index',  \n",
    "      'http://www.welt.de/?service=Rss']\n",
    "\n",
    "countnews={}\n",
    "countnews['tech']=countFeed(trainTech, 'trainTech', should_print=True)\n",
    "countnews['nontech']=countFeed(trainNonTech, 'trainNonTech')\n",
    "countnews['test']=countFeed(test, 'test')\n",
    "\n",
    "print('Number of used trainings samples in categorie tech',countnews['tech'])\n",
    "print('Number of used trainings samples in categorie notech',countnews['nontech'])\n",
    "print('Number of used test samples',countnews['test'])\n",
    "print('--'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMaPR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
