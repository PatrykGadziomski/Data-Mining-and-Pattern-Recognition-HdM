{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Document Classification\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 06.11.2015\n",
    "\n",
    "[Übersicht Versuche im Data Mining Praktikum](http://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "## Abgabe:\n",
    "\n",
    "- **Abzugeben ist das Jupyter Notebook mit dem verlangten Implementierungen und den entsprechenden Ausgaben.**\n",
    "- **Das Notebook ist als .ipynb und als .html abzugeben.**\n",
    "- **Klausurelevante Fragen sind Dokument \"Fragenkatalog Datamining\" zu finden.**\n",
    "- Antworten auf Fragen im Notebook, Diskussionen und Beschreibung der Ergebnisse sind optional (aber empfohlen) und werden nicht bewertet.\n",
    "\n",
    "* [Übersicht Data Mining Praktikum](https://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "\n",
    "# Einführung\n",
    "\n",
    "## Lernziele:\n",
    "\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Dokumentklassifikation: Klassifikation von Dokumenten, insbesondere Emails und RSS Feed\n",
    "* Naive Bayes Classifier: Weit verbreitete Klassifikationsmethode, welche unter bestimmten Randbedingungen sehr gut skaliert.\n",
    "\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "\n",
    "### Parametrische Klassifikation und Naive Bayes Methode\n",
    "\n",
    "Klassifikatoren müssen zu einer gegebenen Eingabe $\\underline{x}$ die zugehörige Klasse $C_i$ bestimmen. Mithilfe der Wahrscheinlichkeitstheorie kann diese Aufgabe wie folgt beschrieben werden: Bestimme für alle möglichen Klassen $C_i$ die bedingte Wahrscheinlichkeit $P(C_i | \\underline{x})$, also die Wahrscheinlichkeit, dass die gegebene Eingabe $\\underline{x}$ in Klasse $C_i$ fällt. Wähle dann die Klasse aus, für welche diese Wahrscheinlichkeit maximal ist.\n",
    "\n",
    "Die Entscheidungsregeln von Klassifikatoren können mit Methoden des \"überwachten Lernens\" aus Trainingsdaten ermittelt werden. Im Fall des **parametrischen Lernens** kann aus den Trainingsdaten die sogenannte **Likelihood-Funktion** $p(\\underline{x} \\mid C_i)$ bestimmt werden. _Anmerkung:_ Allgemein werden mit $p(...)$ kontinuierliche Wahrscheinlichkeitsfunktionen und mit $P(...)$ diskrete Wahrscheinlichkeitswerte bezeichnet. \n",
    "\n",
    "Mithilfe der **Bayes-Formel**\n",
    "$$\n",
    "P(C_i \\mid \\underline{x}) = \\frac{p(\\underline{x} \\mid C_i) \\cdot P(C_i)}{p(\\underline{x})}\n",
    "$$\n",
    "\n",
    "kann aus der Likelihood die **a-posteriori-Wahrscheinlichkeit $P(C_i \\mid \\underline{x})$** berechnet werden. Darin wird $P(C_i)$ die **a-priori-Wahrscheinlichkeit** und $p(\\underline{x})$ die **Evidenz** genannt. Die a-priori-Wahrscheinlichkeit kann ebenfalls aus den Trainingsdaten ermittelt werden. Die Evidenz ist für die Klassifikationsentscheidung nicht relevant, da sie für alle Klassen $C_i$ gleich groß ist.\n",
    "\n",
    "Die Berechnung der Likelihood-Funktion $p(\\underline{x} \\mid C_i)$ ist dann sehr aufwendig, wenn $\\underline{x}=(x_1,x_2,\\ldots,x_Z)$ ein Vektor von voneinander abhängigen Variablen $x_i$ ist. Bei der **Naive Bayes Classification** wird jedoch von der vereinfachenden Annahme ausgegangen, dass die Eingabevariabeln $x_i$ voneinander unabhängig sind. Dann vereinfacht sich die bedingte Verbundwahrscheinlichkeits-Funktion $p(x_1,x_2,\\ldots,x_Z \\mid C_i)$ zu:\n",
    "\n",
    "$$\n",
    "p(x_1,x_2,\\ldots,x_Z \\mid C_i)=\\prod\\limits_{j=1}^Z p(x_j | C_i)\n",
    "$$\n",
    "\n",
    "### Anwendung der Naive Bayes Methode in der Dokumentklassifikation\n",
    "\n",
    "Auf der rechten Seite der vorigen Gleichung stehen nur noch von den jeweils anderen Variablen unabhängige bedingte Wahrscheinlichkeiten. Im Fall der Dokumentklassifikation sind die einzelnen Worte die Variablen, d.h. ein Ausdruck der Form $P(x_j | C_i)$ gibt an mit welcher Wahrscheinlichkeit ein Wort $x_j=w$ in einem Dokument der Klasse $C_i$ vorkommt. \n",
    "Die Menge aller Variablen $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ ist dann die Menge aller Wörter im Dokument. Damit gibt die linke Seite in der oben gegebenen Gleichung die *Wahrscheinlichkeit, dass die Wörter $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ in einem Dokument der Klasse $C_i$ vorkommen*, an.\n",
    "\n",
    "Für jedes Wort _w_ wird aus den Trainingsdaten die Wahrscheinlichkeit $P(w|G)$, mit der das Wort in Dokumenten der Kategorie _Good_ und die Wahrscheinlichkeit $P(w|B)$ mit der das Wort in Dokumenten der Kategorie _Bad_ auftaucht ermittelt. Trainingsdokumente werden in der Form\n",
    "\n",
    "$$\n",
    "tD=(String,Category)\n",
    "$$\n",
    "eingegeben. \n",
    "\n",
    "Wenn \n",
    "\n",
    "* mit der Variable $fc(w,cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ in denen das Wort $w$ enthalten ist\n",
    "* mit der Variable $cc(cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ \n",
    "\n",
    "gezählt wird, dann ist \n",
    "\n",
    "$$\n",
    "P(w|G)=\\frac{fc(w,G)}{cc(G)} \\quad \\quad P(w|B)=\\frac{fc(w,B)}{cc(B)}\n",
    "$$\n",
    "\n",
    "Wird nun nach der Eingabe von $L$ Trainingsdokumenten ein neu zu klassifizierendes Dokument $D$ eingegeben und sei $W(D)$ die Menge aller Wörter in $D$, dann berechnen sich unter der Annahme, dass die Worte in $W(D)$ voneinander unabhängig sind (naive Bayes Annahme) die a-posteriori Wahrscheinlichkeiten zu:\n",
    "\n",
    "$$\n",
    "P(G|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | G) \\right) \\cdot P(G)}{p(D)}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | B) \\right) \\cdot P(B)}{p(D)}\n",
    "$$\n",
    "\n",
    "Die hierfür notwendigen a-priori-Wahrscheinlichkeiten berechnen sich zu \n",
    "\n",
    "$$\n",
    "P(G)=\\frac{cc(G)}{L}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B)=\\frac{cc(B)}{L}\n",
    "$$\n",
    "\n",
    "Die Evidenz $p(D)$ beeinflusst die Entscheidung nicht und kann deshalb ignoriert werden.\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "\n",
    "1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training für die spätere Klassifikation abgespeichert werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Naive-Bayes Classifier wird überwacht trainiert. Dabei wird ein Classifier mit den Wahrscheinlichkeiten trainiert das ein Wort w in einem Dokument der Klasse C_i vorkommt.\n",
    "\n",
    "Die Variablen cc und fc müssen abgespeichert werden:\n",
    "* cc(cat): Anzahl der Trainingsdokumente der Kategorie cat\n",
    "* fc(w,cat): Anzahl der Trainingsdokumente der Kategorie cat in denen das Wort w vorkommt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe der posteriori Wahrscheinlichkeit.\n",
    "\n",
    "Diese wird mit der Likelihood-Funktion, Evidenz und der a-priori Wahrscheinlichkeiten berechnet. \n",
    "* Likelihood-Funktion: Produkt der Wahrscheinlichkeiten dass die einzelnen Wörter aus dem Dokument in der Kategorie C_i sind.\n",
    "* a-priori Wahrscheinlichkeiten: Wahrscheinlichkeit der Kategorie C_i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tatsächlich gegeben?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annahme: Alle Eingabevektoren sind unabhängig voneinander.\n",
    "\n",
    "Nein, da Wörter in Dokumenten voneinander abhängig sind (Semantik)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Betrachten Sie die Formeln für die Berechnung von $P(G|D)$ und $P(B|D)$. Welches Problem stellt sich ein, wenn in der Menge $W(D)$ ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie $G$ vorkommt und ein anderes Wort aus $W(D)$ nicht in den Trainingsdaten der Kategorie $B$ enthalten ist? Wie könnte dieses Problem gelöst werden? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "P(w|G) bzw. P(w|B) sind 0 wenn w nich in G oder B ist, somit würde auch das Produkt in P(G|D) bzw. P(B|D) gleich 0 sein. Dadurch sind dann auch P(G|D) bzw. P(B|D) gleich 0 wodurch D mit einer Wahrscheinlichkeit von 0 in B bzw. G ist. Das Problem könnte gelöst werden wenn man eine Standard wert einführt (zb. 0.1), damit nicht durch ein einzelens Wort in einem Dokument D, das nicht in den Trainingsdaten ist, ein Dokument nicht zugewiesen werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Feature Extraction/ -Selection\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie eine Funktion *getwords(doc)*, der ein beliebiges Dokument in Form einer String-Variablen übergeben wird. In der Funktion soll der String in seine Wörter zerlegt und jedes Wort in _lowercase_ transformiert werden. Wörter, die weniger als eine untere Grenze von Zeichen (z.B. 3) oder mehr als eine obere Grenze von Zeichen (z.B. 20) enthalten, sollen ignoriert werden. Die Funktion soll ein dictionary zurückgeben, dessen _Keys_ die Wörter sind. Die _Values_ sollen für jedes Wort zunächst auf $1$ gesetzt werden.\n",
    "\n",
    "**Tipp:** Benutzen Sie für die Zerlegung des Strings und für die Darstellung aller Wörter mit ausschließlich kleinen Buchstaben die Funktionen *split(), strip('sep')* und *lower()* der Klasse *String*.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import feedparser\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(doc):\n",
    "    word_list = doc.split()\n",
    "    word_dict = {}\n",
    "    list_iligel_symbols = [\"'\",'!','?','.',',',';',':','-','_','*','+','~','#','=','}','[',']','{','(',')','/','$','€',\"\\\\\",'@','\"','%','&','“','‘', '@','’']\n",
    "    for value in word_list:\n",
    "        value_str = value.lower()\n",
    "        for sym in list_iligel_symbols:\n",
    "            value_str = value_str.replace(sym, '')\n",
    "                     \n",
    "        if(len(value_str)>=3 and len(value_str)<=20):\n",
    "            if(value_str in word_dict.keys()):\n",
    "                word_dict[value_str] = 1\n",
    "            else:\n",
    "                word_dict[value_str] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifizierte Version der Methode für die Aufgabe Klassifikation von RSS-Newsfeed\n",
    "def getwordsmodified(doc):\n",
    "    word_list = doc.split()\n",
    "    word_dict = {}\n",
    "    list_iligel_symbols = [\"'\",'!','?','.',',',';',':','-','_','*','+','~','#','=','}','[',']','{','(',')','/','$','€',\"\\\\\",'@','\"','%','&','“','‘', '@','’']\n",
    "    for value in word_list:\n",
    "        value_str = value.lower()\n",
    "        for sym in list_iligel_symbols:\n",
    "            value_str = value_str.replace(sym, '')\n",
    "                     \n",
    "        if(len(value_str)>=3 and len(value_str)<=20):\n",
    "            if(value_str in word_dict.keys()):\n",
    "                word_dict[value_str] += 1\n",
    "            else:\n",
    "                word_dict[value_str] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Classifier\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie den Naive Bayes Classifier für die Dokumentklassifikation. Es bietet sich an die Funktionalität des Klassifikators und das vom Klassifikator gelernte Wissen in einer Instanz einer Klasse _Classifier_ zu kapseln. In diesem Fall kann wie folgt vorgegangen werden:\n",
    "\n",
    "* Im Konstruktor der Klasse wird je ein Dictionary für die Instanzvariablen _fc_ und _cc_ (siehe oben) initialisiert. Dabei ist _fc_ ein verschachteltes Dictionary. Seine Keys sind die bisher gelernten Worte, die Values sind wiederum Dictionaries, deren Keys die Kategorien _Good_ und _Bad_ sind und deren Values zählen wie häufig das Wort bisher in Dokumenten der jeweiligen Kategorie auftrat. Das Dictionary _cc_ hat als Keys die Kategorien _Good_ und _Bad_. Die Values zählen wie häufig Dokumente der jeweiligen Kategorien bisher auftraten.\n",
    "* Im Konstruktor wird ferner der Instanzvariablen _getfeatures_ die Funktion *getwords()* übergeben. Die Funktion _getwords()_ wurde bereits zuvor ausserhalb der Klasse definiert. Sinn dieses Vorgehens ist, dass andere Varianten um Merkmale aus Dokumenten zu extrahieren denkbar sind. Diese Varianten könnten dann ähnlich wie die *getwords()*-Funktion ausserhalb der Klasse definiert und beim Anlegen eines *Classifier*-Objekts der Instanzvariablen _getfeatures_ übergeben werden.  \n",
    "* Der Methode _incf(self,f,cat)_ wird ein Wort _f_ und die zugehörige Kategorie _cat_ des Dokuments in welchem es auftrat übergeben. In der Methode wird der *fc*-Zähler angepasst.\n",
    "* Der Methode _incc(self,cat)_ wird die Kategorie _cat_ des gerade eingelesenen Dokuments übergeben. In der Methode wird der *cc*-Zähler angepasst.\n",
    "* Die Methode _fcount(self,f,cat)_ gibt die Häufigkeit des Worts _f_ in den Dokumenten der Kategorie _cat_ zurück.\n",
    "* Die Methode _catcount(self,cat)_ gibt die Anzahl der Dokumente in der Kategorie _cat_ zurück.\n",
    "* Die Methode _totalcount(self)_ gibt die Anzahl aller Dokumente zurück.\n",
    "* Der Methode _train(self,item,cat)_ wird ein neues Trainingselement, bestehend aus der Betreffzeile (*item*) und der entsprechenden Kategorisierung (*cat*) übergeben. Der String _item_ wird mit der Instanzmethode _getfeatures_ (Diese referenziert *getwords()*) in Worte zerlegt. Für jedes einzelne Wort wird dann *incf(self,f,cat)* aufgerufen. Ausserdem wird für das neue Trainingsdokument die Methode _incc(self,cat)_ aufgerufen.\n",
    "* Die Methode _fprob(self,f,cat)_ berechnet die bedingte Wahrscheinlichkeit $P(f | cat)$ des Wortes _f_ in der Kategorie _cat_ entsprechend der oben angegebenen Formeln, indem sie den aktuellen Stand des Zählers _fc(f,cat)_ durch den aktuellen Stand des Zählers _cc(cat)_ teilt.   \n",
    "* Die Methode _fprob(self,f,cat)_ liefert evtl. ungewollt extreme Ergebnisse, wenn noch wenig Wörter im Klassifizierer verbucht sind. Kommt z.B. ein Wort erst einmal in den Trainingsdaten vor, so wird seine Auftrittswahrscheinlichkeit in der Kategorie in welcher es nicht vorkommt gleich 0 sein. Um extreme Wahrscheinlichkeitswerte im Fall noch selten vorkommender Werte zu vermeiden, soll zusätzlich zur Methode _fprob(self,f,cat)_ die Methode _weightedprob(self,f,cat)_ implementiert und angewandt werden. Der von ihr zurückgegebene Wahrscheinlichkeitswert könnte z.B. wie folgt berechnet werden:$$wprob=\\frac{initprob+count \\cdot fprob(self,f,cat)}{1+count},$$ wobei $initprob$ ein initialer Wahrscheinlichkeitswert (z.B. 0.5) ist, welcher zurückgegeben werden soll, wenn das Wort noch nicht in den Trainingsdaten aufgetaucht ist. Die Variable $count$ zählt wie oft das Wort $f$ bisher in den Trainingsdaten auftrat. Wie zu erkennen ist, nimmt der Einfluss der initialen Wahrscheinlichkeit ab, je häufiger das Wort in den Trainingsdaten auftrat.\n",
    "* Nach dem Training soll ein beliebiges neues Dokument (Text-String) eingegeben werden können. Für dieses soll mit der Methode _prob(self,item,cat)_ die a-posteriori-Wahrscheinlichkeit $P(cat|item)$ (Aufgrund der Vernachlässigung der Evidenz handelt es sich hierbei genaugenommen um das Produkt aus a-posteriori-Wahrscheinlichkeit und Evidenz), mit der das Dokument _item_ in die Kategorie _cat_ fällt berechnet werden. Innerhalb der Methode _prob(self,item,cat)_ soll zunächst die Methode _weightedprob(self,f,cat)_ für alle Wörter $f$ im Dokument _item_ aufgerufen werden. Die jeweiligen Rückgabewerte von _weightedprob(self,f,cat)_ werden multipliziert. Das Produkt der Rückgabewerte von _weightedprob(self,f,cat)_ über alle Wörter $f$ im Dokument muss schließlich noch mit der a-priori Wahrscheinlichkeit $P(G)$ bzw. $P(B)$ entsprechend der oben aufgeführten Formeln multipliziert werden. Das Resultat des Produkts wird an das aufrufende Programm zurück gegeben, die Evidenz wird also vernachlässigt (wie oben begründet).\n",
    "\n",
    "\n",
    "\n",
    "Ein Dokument _item_ wird schließlich der Kategorie _cat_ zugeteilt, für welche die Funktion _prob(self,item,cat)_ den höheren Wert zurück gibt. Da die Rückgabewerte in der Regel sehr klein sind, werden in der Regel folgende Werte angezeigt:\n",
    "* Wenn mit $g$ der Rückgabewert von _prob(self,item,cat=G)_ und mit $b$ der Rückgabewert von _prob(self,item,cat=B)_ bezeichnet wird dann ist die Wahrscheinlichkeit, dass $item$ in die Kategorie $G$ fällt, gleich:\n",
    "$$\n",
    "\\frac{g}{g+b}\n",
    "$$\n",
    "* und die Wahrscheinlichkeit, dass $item$ in die Kategorie $B$ fällt, gleich:\n",
    "$$\n",
    "\\frac{b}{g+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    categories = []\n",
    "    \n",
    "    def __init__(self, getfeatures, categories):\n",
    "        self.categories = categories\n",
    "        self.cc = {}\n",
    "        for category in self.categories:\n",
    "            self.cc[category] = 0\n",
    "        self.fc = {}\n",
    "        self.getfeatures = getfeatures\n",
    "    \n",
    "    def incf(self, cat, w, count):\n",
    "        if w in self.fc.keys():\n",
    "            if cat in self.fc[w].keys():\n",
    "                self.fc[w][cat] += count \n",
    "            else:\n",
    "                self.fc[w][cat] = count \n",
    "        elif w not in self.fc.keys():\n",
    "            self.fc[w] = {}\n",
    "            for category in self.categories:\n",
    "                self.fc[w][category] = 0\n",
    "\n",
    "            self.fc[w][cat] += count       \n",
    "\n",
    "    def incc(self, cat):\n",
    "        self.cc[cat] += 1\n",
    "\n",
    "    def fcount(self, cat, w):\n",
    "        if w in self.fc.keys():\n",
    "            x = self.fc[w][cat]\n",
    "        else:\n",
    "            x = 0\n",
    "        return x\n",
    "        \n",
    "    def catcount(self, cat):\n",
    "        return self.cc[cat]\n",
    "\n",
    "    def totalcount(self):\n",
    "        return sum(self.cc.values())\n",
    "\n",
    "    def train(self, item, cat):\n",
    "        word_dict = self.getfeatures(item)\n",
    "        for key in word_dict.keys():\n",
    "            self.incf(cat, key, word_dict[key])\n",
    "        self.incc(cat)\n",
    "    \n",
    "    def fprob(self, cat, w):\n",
    "        x = self.fcount(cat, w)/self.catcount(cat)\n",
    "        return x\n",
    "\n",
    "    def weightedprob(self, cat, w):\n",
    "        fProb = self.fprob(cat, w)\n",
    "        initProb = 0.5\n",
    "        count = 0\n",
    "        for value in self.categories:\n",
    "            count += self.fcount(value, w)\n",
    "        \n",
    "        x = (initProb + count*fProb)/ (1+count)\n",
    "        return x\n",
    "    \n",
    "    def prob(self, item, cat):\n",
    "        word_dict = self.getfeatures(item) \n",
    "        prodProb = 1\n",
    "        for value in word_dict:\n",
    "            prodProb *= self.weightedprob(cat, value)\n",
    "        catCount = self.catcount(cat)\n",
    "        totCount = self.totalcount()\n",
    "        apriori = catCount/totCount\n",
    "        x = prodProb*apriori\n",
    "        return x\n",
    "\n",
    "    def decision(self,item):\n",
    "        g = self.prob(item, self.categories[0])\n",
    "        b = self.prob(item, self.categories[1])\n",
    "        good = g/(g+b)\n",
    "        bad = b/(g+b)\n",
    "        result = ''\n",
    "        if b < g:\n",
    "            print(f\"der Text gehört mit einer Wahrscheinlichkeit von {good} zu der Kategorie '{self.categories[0]}'\")\n",
    "            result = self.categories[0]\n",
    "        else:\n",
    "            print(f\"der Text gehört mit einer Wahrscheinlichkeit von {bad} zu der Kategorie '{self.categories[1]}'\")\n",
    "            result = self.categories[1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "**Aufgabe:**\n",
    "Instanzieren Sie ein Objekt der Klasse _Classifier_ und übergeben Sie der _train()_ Methode dieser Klasse mindestens 8 kategorisierte Dokumente (Betreffzeilen als Stringvariablen zusammen mit der Kategorie Good oder Bad). Definieren Sie dann ein beliebig neues Dokument und berechnen Sie für dieses die Kategorie, in welches es mit größter Wahrscheinlichkeit fällt. Benutzen Sie für den Test das in der\n",
    "[NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/07classificationNaiveBayes.html)\n",
    "ausführlich beschriebene Beispiel zu implementieren. Berechnen Sie die Klassifikatorausgabe des Satzes _the money jumps_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/train.csv',index_col=0)\n",
    "\n",
    "data = data[data['text'].notna()]\n",
    "\n",
    "cats = []\n",
    "for value in data[\"label\"]:\n",
    "    if(value == 0):\n",
    "        cats.append(\"Good\")\n",
    "    else:\n",
    "        cats.append(\"Bad\")\n",
    "\n",
    "data[\"category\"] = cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = data.head(10000)\n",
    "category = [\"Good\", \"Bad\"]\n",
    "classifier = Classifier(getwords, category)\n",
    "classifier_mod = Classifier(getwordsmodified, category)\n",
    "\n",
    "texts = []\n",
    "cats = []\n",
    "for value in test_data[\"text\"]:\n",
    "    texts.append(value)\n",
    "\n",
    "for value in test_data[\"category\"]:\n",
    "    cats.append(value)\n",
    "\n",
    "for i in range(0,50):\n",
    "    classifier.train(texts[i], cats[i])\n",
    "\n",
    "for i in range(0,50):\n",
    "    classifier_mod.train(texts[i], cats[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7091537106296171 zu der Kategorie 'Good'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6736648675294423 zu der Kategorie 'Good'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"The money jumps.\"\n",
    "\n",
    "classifier.decision(test_string)\n",
    "classifier_mod.decision(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von RSS Newsfeeds\n",
    "Mit dem unten gegebenen Skript werden Nachrichten verschiedener Newsserver geladen und ausgegeben. Ändern Sie diese Methode ab, damit diese Strings gespeichert werden und für ein Training benutzt werden können. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used trainings samples in categorie tech 160\n",
      "Number of used trainings samples in categorie notech 115\n",
      "Number of used test samples 85\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def countFeed(feedList, title, should_print=False):\n",
    "    if should_print:\n",
    "        print(f\"--------------------News from {title}------------------------\")\n",
    "    count = 0\n",
    "    for feed in feedList:\n",
    "        if should_print:\n",
    "            print()\n",
    "            print(\"*\"*30)\n",
    "            print(feed)\n",
    "        f=feedparser.parse(feed)\n",
    "        for e in f.entries:\n",
    "            if hasattr(e, 'title') and hasattr(e, 'description'):\n",
    "                if should_print:\n",
    "                    print('\\n---------------------------')\n",
    "                fulltext=stripHTML(e.title+' '+e.description)\n",
    "                if should_print:\n",
    "                    print(fulltext)\n",
    "                count += 1\n",
    "    if should_print:\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "    return count\n",
    "\n",
    "# Unsere Funktion zum Abspeichern der Strings\n",
    "def getTextFeed(feedList, title, cat):\n",
    "    text = {}\n",
    "    for feed in feedList:\n",
    "        if(feed == 'http://rss.golem.de/rss.php?r=sw&feed=RSS0.91'):\n",
    "            cat = 'Tech'\n",
    "        elif(feed == 'http://www.welt.de/?service=Rss' or feed == 'http://newsfeed.zeit.de/politik/index'):\n",
    "            cat = 'NonTech'\n",
    "        f=feedparser.parse(feed)\n",
    "        for e in f.entries:\n",
    "            if hasattr(e, 'title') and hasattr(e, 'description'):\n",
    "                fulltext=stripHTML(e.title+' '+e.description)\n",
    "                text[fulltext] = cat\n",
    "    return text\n",
    "                \n",
    "def stripHTML(h):\n",
    "    p=''\n",
    "    s=0\n",
    "    for c in h:\n",
    "        if c=='<': \n",
    "            s=1\n",
    "        elif c=='>':\n",
    "            s=0\n",
    "            p+=' '\n",
    "        elif s==0:\n",
    "            p+=c\n",
    "    return p\n",
    "\n",
    "trainTech=['http://rss.chip.de/c/573/f/7439/index.rss',\n",
    "           #'http://feeds.feedburner.com/netzwelt',\n",
    "           'http://rss1.t-online.de/c/11/53/06/84/11530684.xml',\n",
    "           'http://www.computerbild.de/rssfeed_2261.xml?node=13',\n",
    "           'http://www.heise.de/newsticker/heise-top-atom.xml']\n",
    "\n",
    "trainNonTech=['http://newsfeed.zeit.de/index',\n",
    "              'http://newsfeed.zeit.de/wirtschaft/index',\n",
    "              'http://www.welt.de/politik/?service=Rss',\n",
    "              'http://www.spiegel.de/schlagzeilen/tops/index.rss',\n",
    "              'https://rss.sueddeutsche.de/alles',\n",
    "              'http://www.faz.net/rss/aktuell/']\n",
    "\n",
    "test=['http://rss.golem.de/rss.php?r=sw&feed=RSS0.91',\n",
    "      'http://newsfeed.zeit.de/politik/index',  \n",
    "      'http://www.welt.de/?service=Rss']\n",
    "\n",
    "countnews={}\n",
    "countnews['tech']=countFeed(trainTech, 'trainTech')\n",
    "countnews['nontech']=countFeed(trainNonTech, 'trainNonTech')\n",
    "countnews['test']=countFeed(test, 'test')\n",
    "\n",
    "print('Number of used trainings samples in categorie tech',countnews['tech'])\n",
    "print('Number of used trainings samples in categorie notech',countnews['nontech'])\n",
    "print('Number of used test samples',countnews['test'])\n",
    "print('--'*30)\n",
    "\n",
    "news_text={}\n",
    "news_text['tech'] = {}\n",
    "news_text['nontech'] = {}\n",
    "news_text['test'] = {}\n",
    "news_text['tech'] = getTextFeed(trainTech, 'trainTech', 'Tech')\n",
    "news_text['nontech'] = getTextFeed(trainNonTech, 'trainNonTech', 'NonTech')\n",
    "news_text['test'] = getTextFeed(test, 'test','')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgaben:**\n",
    "1. Trainieren Sie Ihren Naive Bayes Classifier mit allen Nachrichten der in den Listen _trainTech_ und _trainNonTech_ definierten Servern. Weisen Sie für das Training allen Nachrichten aus _trainTech_ die Kategorie _Tech_ und allen Nachrichten aus _trainNonTech_ die Kategorie _NonTech_ zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = [\"Tech\", \"NonTech\"]\n",
    "\n",
    "classifier_rss = Classifier(getwords, categories)\n",
    "classifier_rss_mod = Classifier(getwordsmodified, categories)\n",
    "\n",
    "tech_texts = []\n",
    "\n",
    "tech_texts = news_text['tech'].keys()\n",
    "nontech_texts = news_text['nontech'].keys()\n",
    "test_texts = news_text['test'].keys()\n",
    "\n",
    "for text in tech_texts:\n",
    "    classifier_rss.train(text, \"Tech\")\n",
    "for text in nontech_texts:\n",
    "    classifier_rss.train(text, \"NonTech\")\n",
    "\n",
    "for text in tech_texts:\n",
    "    classifier_rss_mod.train(text, \"Tech\")\n",
    "for text in nontech_texts:\n",
    "    classifier_rss_mod.train(text, \"NonTech\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Nach dem Training sollen alle Nachrichten aus der Liste _test_ vom Naive Bayes Classifier automatisch klassifiziert werden. Gehen Sie davon aus, dass alle Nachrichten von [http://rss.golem.de/rss.php?r=sw&feed=RSS0.91](http://rss.golem.de/rss.php?r=sw&feed=RSS0.91) tatsächlich von der Kategorie _Tech_ sind und alle Nachrichten von den beiden anderen Servern in der Liste _test_ von der Kategorie _NonTech_ sind. Bestimmen Sie die _Konfusionsmatrix_ und die _Accuracy_ sowie für beide Klassen _Precision, Recall_ und _F1-Score_. Diese Qualitätsmetriken sind z.B. in [NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/06classificationMetrics.html) definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8703032338847528 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7922977248907801 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6702777705635751 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5231735863122527 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5435865472216501 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7400695937579748 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7031518074023397 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6624622607001405 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9172658733382544 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5955022835901272 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.751299922690387 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5235414718864873 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7064808918405451 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6404277678658687 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6193907547681168 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.666406806970004 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5097661603016157 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6637925696888961 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6244721837549464 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.773227873651914 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5491563787664442 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8093679990990352 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5204907959042407 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5190889842279527 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6923108427517811 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6126646070218452 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.538228380275574 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5349934843110487 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7503178736055284 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6684910528115904 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6199712980859325 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5693309928560245 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5009864631138375 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6389587389968813 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5753115265304078 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8625084654084088 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8108202343081503 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6822309734049762 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5485060177396895 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6752646330213794 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9966466893344129 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7301147654759292 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5369420089913732 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8538454835543049 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6179518040338191 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9611292463134227 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7275200604788746 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6128977502116322 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9561049519278443 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6138633360628631 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9466332179945044 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7634619380642349 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7255430541049508 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7707398670680289 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6911007959232752 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9824061922460401 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9985457352388946 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6269431240640081 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8859972578815899 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.755646773521891 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9668850348058529 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8817303009101173 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9998628768906833 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7229898584307961 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8847710518592188 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5924698852730473 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5461813543694181 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6424282551413417 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9412435798488283 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6624381961124481 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8349137499717408 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9455175290618745 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6024585171103851 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8824100715415203 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9747384419446289 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9541913985986553 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9970406896326385 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7158679712259461 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8234886891613852 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6457143976083606 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8253274049766685 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9856658968707626 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6739602543570614 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.983750947716873 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9116242805593168 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9232313386403626 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9125409834837261 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.772901585658714 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5128651825892475 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7006913581771589 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8275899237891905 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6223747273914083 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7439072421594289 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9596465400333385 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7985689069200349 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7950526519347112 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6792227208871949 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8261659374931435 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7722202094210259 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6482720452997229 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7892378394056007 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6784661711861176 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5169984911062524 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5839008406488435 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8544137512457908 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5422831462799418 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8904753324774013 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5292260089584992 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5796123296505172 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7215096470157721 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5287610198388475 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.545508083813366 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5305928446324758 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7669562721774535 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7245914481370257 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6390558298673408 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5718969792940878 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7499597854358057 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.762793088047698 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5329760846836641 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9295365598107552 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8059986042329667 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7247892910051463 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5925298969387404 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.663953823274343 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9978834082602404 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8347123701813682 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5584523285069611 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9035060114113447 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7843711413394363 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.979380619904919 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8054652965215011 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7462238867339509 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9817430877961125 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5745333522906925 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9715178737843628 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.851809560628125 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.676866325865385 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9126528360259952 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7148094155820942 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9972688171098623 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9992376621901309 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6685990911034152 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8728024400735613 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.809243245406774 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9913830781051444 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9548218784586601 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9999312498520178 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8631231852128246 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9513679815467995 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6483258908486917 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5331412165995104 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7433199294667163 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9545033694815985 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7448439943840015 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9240265112497319 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.961049717034817 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5907257471855589 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9011099675333354 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9697807502815717 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9569213053392779 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9985943128960969 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.803648609008381 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8597030261069577 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5642276827654967 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8620930930723636 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.98320395400021 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6245279394409585 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9869414650576253 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9657777293497375 zu der Kategorie 'NonTech'\n"
     ]
    }
   ],
   "source": [
    "pred_cat = []\n",
    "test_true = []\n",
    "pred_cat_mod = []\n",
    "test_true_mod = []\n",
    "\n",
    "for text in test_texts:\n",
    "    test_true.append(news_text['test'][text])\n",
    "    pred_cat.append(classifier_rss.decision(text))\n",
    "    \n",
    "for text in test_texts:\n",
    "    test_true_mod.append(news_text['test'][text])\n",
    "    pred_cat_mod.append(classifier_rss_mod.decision(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_true, pred_cat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "# TP | FN\n",
    "#--------\n",
    "# FP | TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGwCAYAAABSAee3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyN0lEQVR4nO3de3RU9b3//9cEyCSBTCBgbhJCkHCTi0gQQlVABY3KD8Rj8WAtWKBFEM1JLf6EqrGVRDiniMoxIm0heqTg0oI35NJqQEVaEkEpUIQaIAgxgGDInczs7x/I1DFcZjKTzGU/H2vttZzP7Ms7lPLO+/357L0thmEYAgAAQSnM3wEAAICmI5EDABDESOQAAAQxEjkAAEGMRA4AQBAjkQMAEMRI5AAABLHW/g7AGw6HQ0eOHFF0dLQsFou/wwEAeMgwDJ0+fVpJSUkKC2u+2rK2tlb19fVenyc8PFwRERE+iMh3gjqRHzlyRMnJyf4OAwDgpdLSUnXu3LlZzl1bW6vUlHYqK7d7fa6EhASVlJQEVDIP6kQeHR0tSTr4aVfZ2jFLgNB0R49+/g4BaDYNOqOPtNb573lzqK+vV1m5XQeLu8oW3fRcUXHaoZRBB1RfX08i95Vz7XRbuzCv/scBAllrSxt/hwA0n+8eEt4S06Ptoi1qF9306zgUmFO4QZ3IAQBwl91wyO7F20XshsN3wfgQiRwAYAoOGXKo6Zncm2ObE/1oAACCGBU5AMAUHHLIm+a4d0c3HxI5AMAU7IYhu9H09rg3xzYnWusAAAQxKnIAgCmE6mI3EjkAwBQcMmQPwUROax0AgCBGRQ4AMAVa6wAABDFWrQMAgIBDIgcAmILDB1tT5eXlyWKxKCsryzlmGIZycnKUlJSkyMhIjRgxQrt27fL43CRyAIAp2L9bte7N1hTbtm3TSy+9pP79+7uML1iwQAsXLtTixYu1bds2JSQkaNSoUTp9+rRH5yeRAwBMwW54v3mqsrJS99xzj5YuXaoOHTo4xw3D0KJFizR37lyNHz9effv2VUFBgaqrq7VixQqPrkEiBwDAAxUVFS5bXV3dBfedOXOmbrvtNt10000u4yUlJSorK9Po0aOdY1arVcOHD9eWLVs8iodEDgAwBV/NkScnJysmJsa55eXlnfd6K1eu1Keffnre78vKyiRJ8fHxLuPx8fHO79zF7WcAAFNwyCK7LF4dL0mlpaWy2WzOcavV2mjf0tJSPfTQQ9qwYYMiIiIueE6LxTUewzAajV0KiRwAAA/YbDaXRH4+xcXFKi8v16BBg5xjdrtdmzdv1uLFi7V3715JZyvzxMRE5z7l5eWNqvRLobUOADAFh+H95q4bb7xRO3fu1I4dO5xbenq67rnnHu3YsUPdunVTQkKCNm7c6Dymvr5emzZt0rBhwzz6uajIAQCmYPeyte7JsdHR0erbt6/LWNu2bdWxY0fneFZWlnJzc5WWlqa0tDTl5uYqKipKEydO9CguEjkAAH4we/Zs1dTUaMaMGTp58qSGDBmiDRs2KDo62qPzkMgBAKbQkhX5+RQWFrp8tlgsysnJUU5OjlfnJZEDAEzBYVjkMLxYte7Fsc2JxW4AAAQxKnIAgCn4u7XeXEjkAABTsCtMdi8a0XYfxuJLJHIAgCkYXs6RG8yRAwAAX6MiBwCYAnPkAAAEMbsRJrvhxRx5E95H3hJorQMAEMSoyAEApuCQRQ4v6leHArMkJ5EDAEwhVOfIaa0DABDEqMgBAKbg/WI3WusAAPjN2TlyL16aQmsdAAD4GhU5AMAUHF4+a51V6wAA+BFz5AAABDGHwkLyPnLmyAEACGJU5AAAU7AbFtm9eBWpN8c2JxI5AMAU7F4udrPTWgcAAL5GRQ4AMAWHESaHF6vWHaxaBwDAf2itAwCAgENFDgAwBYe8W3nu8F0oPkUiBwCYgvcPhAnMJnZgRgUAANxCRQ4AMAXvn7UemLUviRwAYAqh+j5yEjkAwBRCtSIPzKgAAIBbqMgBAKbg/QNhArP2JZEDAEzBYVjk8OY+8gB9+1lg/noBAADcQkUOADAFh5et9UB9IAyJHABgCt6//SwwE3lgRgUAQJDLz89X//79ZbPZZLPZlJGRoffee8/5/eTJk2WxWFy2oUOHenwdKnIAgCnYZZHdi4e6eHps586d9fTTT6t79+6SpIKCAo0dO1bbt2/XlVdeKUm65ZZbtGzZMucx4eHhHsdFIgcAmIKvWusVFRUu41arVVartdH+Y8aMcfk8b9485efna+vWrc5EbrValZCQ0OSYJFrrAAB4JDk5WTExMc4tLy/vksfY7XatXLlSVVVVysjIcI4XFhYqLi5OPXr00LRp01ReXu5xPFTkAABTsMvz9vgPj5ek0tJS2Ww25/j5qvFzdu7cqYyMDNXW1qpdu3ZavXq1+vTpI0nKzMzUXXfdpZSUFJWUlOixxx7TDTfcoOLi4oue84dI5AAAU/BVa/3c4jV39OzZUzt27NCpU6f0xhtvaNKkSdq0aZP69OmjCRMmOPfr27ev0tPTlZKSonfffVfjx493Oy4SOQDAFPzx0pTw8HDnYrf09HRt27ZNzz77rJYsWdJo38TERKWkpGjfvn0eXYM5cgAAWohhGKqrqzvvdydOnFBpaakSExM9OicVOQDAFAwv30dueHjsnDlzlJmZqeTkZJ0+fVorV65UYWGh1q1bp8rKSuXk5OjOO+9UYmKiDhw4oDlz5qhTp0664447PLoOiRwAYAot3Vr/+uuvde+99+ro0aOKiYlR//79tW7dOo0aNUo1NTXauXOnXn75ZZ06dUqJiYkaOXKkVq1apejoaI+uQyIHAKAZ/OEPf7jgd5GRkVq/fr1PrkMiBwCYQqi+xpREDgAwBbuXbz/z5tjmFJhRAQAAt1CRAwBMgdY6AABBzKEwObxoRHtzbHMKzKgAAIBbqMgBAKZgNyyye9Ee9+bY5kQiBwCYAnPkAAAEMcPLt58ZXhzbnAIzKgAA4BYqcgCAKdhlkd2Ll6Z4c2xzIpEDAEzBYXg3z+0wfBiMD9FaBwAgiFGR46JWPh+nZXlJGjf1mO7/zVdqOCMtn5+obe/bdPRguNraHBp43WlNmXNEHRMa/B0u0CS3//S4bvvpCcUn10uSDu6N0KvPxKvoA5ufI4MvObxc7ObNsc2JRI4L2rsjUmv/r6NS+9Q4x+pqwrR/Z5QmZn2tbn1qVPltK734xOV6YnI3LV73hR+jBZru2NE2+mNuoo4csEqSRt31jXKWHdDM0T108IsIP0cHX3HIIocX89zeHNuc/P7rxQsvvKDU1FRFRERo0KBB+vDDD/0dEiTVVIVp/gMpyvrvUkXH2J3jbW0OPb3qXxr+/51Scvc69R5UrRlPHda+z6NUfriNHyMGmu5vG2O07X2bvvrSqq++tGr5/ETVVoWp16Aqf4cGXJJfE/mqVauUlZWluXPnavv27bruuuuUmZmpQ4cO+TMsSFo8p7OuubFCV19fecl9qypayWIx1PZ7CR8IVmFhhoaPPSlrlEN7itr6Oxz40Lknu3mzBSK/ttYXLlyoKVOmaOrUqZKkRYsWaf369crPz1deXp4/QzO1wjXttX9npJ5fe+lWeX2tRX/MTdLIO06qbbSjBaIDmkfXXjVa9PZ+hVsdqqkK02+mdNWhfbTVQ0mozpH7Lar6+noVFxdr9OjRLuOjR4/Wli1bzntMXV2dKioqXDb4VvlXbZT/+OWa/fxBhUdc/F6LhjNS7v1dZTikB/IOt1CEQPM4/C+rZozqoYduT9M7L3fSw88eUpe0Wn+HBVyS3yry48ePy263Kz4+3mU8Pj5eZWVl5z0mLy9PTz75ZEuEZ1r7P4/SqeNt9MAtPZ1jDrtFO7e21VvLOumdA5+pVauzSXzeL7qqrDRcC17bTzWOoNdwJsy52G3f51HqeVW1xk09puceSfZzZPAVh7x81nqALnbz+6p1i8X1D8YwjEZj5zz66KPKzs52fq6oqFByMv8n86WrrjutJe//02Xsd//VRcnda/XjmeUuSfyrEqsWvL5ftljmxhGa2oQH6BNA0CSGl6vWDRK5q06dOqlVq1aNqu/y8vJGVfo5VqtVVqu1JcIzrah2DnXt5dpOjIhyKLqDXV171creIP12Wqr274zUb17+Ug67Rd+Un/1rFN3ezj98CEr3/f9Hte39aB07Eq7IdnaNGHtK/YdV6tf3dPN3aPAh3n7mY+Hh4Ro0aJA2btyoO+64wzm+ceNGjR071l9h4RKOHQ3X1g0xkqQZo3q5fLfg9f0aMOzSq9yBQNP+sgb96vlDio1rUPXpVirZE6Ff39NNn26O9ndowCX5tbWenZ2te++9V+np6crIyNBLL72kQ4cOafr06f4MCz/w32/sd/53QnK91h/Z4b9ggGbwzC+ZojODUF217tdEPmHCBJ04cUK/+c1vdPToUfXt21dr165VSkqKP8MCAIQgWuvNZMaMGZoxY4a/wwAAICj5PZEDANASQvVZ6yRyAIAphGprPTBn7gEAgFuoyAEAphCqFTmJHABgCqGayGmtAwAQxKjIAQCmEKoVOYkcAGAKhry7hSxQ3yRBIgcAmEKoVuTMkQMAEMRI5AAAUzhXkXuzeSI/P1/9+/eXzWaTzWZTRkaG3nvvPef3hmEoJydHSUlJioyM1IgRI7Rr1y6Pfy4SOQDAFFo6kXfu3FlPP/20ioqKVFRUpBtuuEFjx451JusFCxZo4cKFWrx4sbZt26aEhASNGjVKp0+f9ug6JHIAAJrBmDFjdOutt6pHjx7q0aOH5s2bp3bt2mnr1q0yDEOLFi3S3LlzNX78ePXt21cFBQWqrq7WihUrPLoOiRwAYAq+qsgrKipctrq6ukte2263a+XKlaqqqlJGRoZKSkpUVlam0aNHO/exWq0aPny4tmzZ4tHPRSIHAJiCYVi83iQpOTlZMTExzi0vL++C19y5c6fatWsnq9Wq6dOna/Xq1erTp4/KysokSfHx8S77x8fHO79zF7efAQDggdLSUtlsNudnq9V6wX179uypHTt26NSpU3rjjTc0adIkbdq0yfm9xeI6724YRqOxSyGRAwBMwVfvIz+3Ct0d4eHh6t69uyQpPT1d27Zt07PPPqtHHnlEklRWVqbExETn/uXl5Y2q9EuhtQ4AMIWWXrV+PoZhqK6uTqmpqUpISNDGjRud39XX12vTpk0aNmyYR+ekIgcAoBnMmTNHmZmZSk5O1unTp7Vy5UoVFhZq3bp1slgsysrKUm5urtLS0pSWlqbc3FxFRUVp4sSJHl2HRA4AMIXvL1hr6vGe+Prrr3Xvvffq6NGjiomJUf/+/bVu3TqNGjVKkjR79mzV1NRoxowZOnnypIYMGaINGzYoOjrao+uQyAEAptDSz1r/wx/+cNHvLRaLcnJylJOT0+SYJBI5AMAkWroibyksdgMAIIhRkQMATMHwsrUeqBU5iRwAYAqGJMPw7vhARGsdAIAgRkUOADAFhyyy+ODJboGGRA4AMAVWrQMAgIBDRQ4AMAWHYZGlBR8I01JI5AAAUzAML1etB+iydVrrAAAEMSpyAIAphOpiNxI5AMAUSOQAAASxUF3sxhw5AABBjIocAGAKobpqnUQOADCFs4ncmzlyHwbjQ7TWAQAIYlTkAABTYNU6AABBzJB37xQP0M46rXUAAIIZFTkAwBRorQMAEMxCtLdOIgcAmIOXFbkCtCJnjhwAgCBGRQ4AMAWe7AYAQBAL1cVutNYBAAhiVOQAAHMwLN4tWAvQipxEDgAwhVCdI6e1DgBAEKMiBwCYAw+EAQAgeIXqqnW3Evlzzz3n9gkffPDBJgcDAAA841Yif+aZZ9w6mcViIZEDAAJXgLbHveFWIi8pKWnuOAAAaFah2lpv8qr1+vp67d27Vw0NDb6MBwCA5mH4YAtAHify6upqTZkyRVFRUbryyit16NAhSWfnxp9++mmfBwgAQDDKy8vT4MGDFR0drbi4OI0bN0579+512Wfy5MmyWCwu29ChQz26jseJ/NFHH9Vnn32mwsJCRUREOMdvuukmrVq1ytPTAQDQQiw+2Ny3adMmzZw5U1u3btXGjRvV0NCg0aNHq6qqymW/W265RUePHnVua9eu9eg6Ht9+tmbNGq1atUpDhw6VxfLvH6pPnz7617/+5enpAABoGT66j7yiosJl2Gq1ymq1Ntp93bp1Lp+XLVumuLg4FRcX6/rrr3c5PiEhoclheVyRHzt2THFxcY3Gq6qqXBI7AAChKDk5WTExMc4tLy/PreO+/fZbSVJsbKzLeGFhoeLi4tSjRw9NmzZN5eXlHsXjcUU+ePBgvfvuu5o1a5YkOZP30qVLlZGR4enpAABoGT6qyEtLS2Wz2ZzD56vGGx1qGMrOzta1116rvn37OsczMzN11113KSUlRSUlJXrsscd0ww03qLi42K3zSk1I5Hl5ebrlllu0e/duNTQ06Nlnn9WuXbv0ySefaNOmTZ6eDgCAluGjt5/ZbDaXRO6OBx54QJ9//rk++ugjl/EJEyY4/7tv375KT09XSkqK3n33XY0fP96tc3vcWh82bJg+/vhjVVdX64orrtCGDRsUHx+vTz75RIMGDfL0dAAAhLRZs2bprbfe0gcffKDOnTtfdN/ExESlpKRo3759bp+/Sc9a79evnwoKCppyKAAAftHSrzE1DEOzZs3S6tWrVVhYqNTU1Esec+LECZWWlioxMdHt6zQpkdvtdq1evVp79uyRxWJR7969NXbsWLVuzTtYAAABqoXffjZz5kytWLFCb775pqKjo1VWViZJiomJUWRkpCorK5WTk6M777xTiYmJOnDggObMmaNOnTrpjjvucPs6Hmfef/zjHxo7dqzKysrUs2dPSdIXX3yhyy67TG+99Zb69evn6SkBAAg5+fn5kqQRI0a4jC9btkyTJ09Wq1attHPnTr388ss6deqUEhMTNXLkSK1atUrR0dFuX8fjRD516lRdeeWVKioqUocOHSRJJ0+e1OTJk/Xzn/9cn3zyiaenBACg+flosZvbu1+iFx8ZGan169c3PZ7veJzIP/vsM5ckLkkdOnTQvHnzNHjwYK8DAgCgOViMs5s3xwcij1et9+zZU19//XWj8fLycnXv3t0nQQEA4HNmfmlKRUWFc8vNzdWDDz6o119/XYcPH9bhw4f1+uuvKysrS/Pnz2/ueAEAwPe41Vpv3769y+NXDcPQj3/8Y+fYuXmAMWPGyG63N0OYAAB4qYXnyFuKW4n8gw8+aO44AABoXi18+1lLcSuRDx8+vLnjAAAATdDkJ7hUV1fr0KFDqq+vdxnv37+/10EBAOBzZq7Iv+/YsWO677779N577533e+bIAQABKUQTuce3n2VlZenkyZPaunWrIiMjtW7dOhUUFCgtLU1vvfVWc8QIAAAuwOOK/P3339ebb76pwYMHKywsTCkpKRo1apRsNpvy8vJ02223NUecAAB4J0RXrXtckVdVVSkuLk6SFBsbq2PHjkk6+0a0Tz/91LfRAQDgI+ee7ObNFoia9GS3vXv3SpKuuuoqLVmyRF999ZVefPFFj167BgAAvOdxaz0rK0tHjx6VJD3xxBO6+eab9eqrryo8PFzLly/3dXwAAPhGiC528ziR33PPPc7/HjhwoA4cOKB//vOf6tKlizp16uTT4AAAwMU1+T7yc6KionT11Vf7IhYAAJqNRV6+/cxnkfiWW4k8Ozvb7RMuXLiwycEAAADPuJXIt2/f7tbJvv9ilZY0MmeKWoVH+OXaQHM79scz/g4BaDaOmlppxpstc7EQvf2Ml6YAAMwhRBe7eXz7GQAACBxeL3YDACAohGhFTiIHAJiCt09nC5knuwEAgMBBRQ4AMIcQba03qSJ/5ZVX9KMf/UhJSUk6ePCgJGnRokV6880WuoUAAABPGT7YApDHiTw/P1/Z2dm69dZbderUKdntdklS+/bttWjRIl/HBwAALsLjRP78889r6dKlmjt3rlq1auUcT09P186dO30aHAAAvhKqrzH1eI68pKREAwcObDRutVpVVVXlk6AAAPC5EH2ym8cVeWpqqnbs2NFo/L333lOfPn18ERMAAL4XonPkHlfkv/rVrzRz5kzV1tbKMAz9/e9/15/+9Cfl5eXp97//fXPECAAALsDjRH7fffepoaFBs2fPVnV1tSZOnKjLL79czz77rO6+++7miBEAAK+F6gNhmnQf+bRp0zRt2jQdP35cDodDcXFxvo4LAADfCtH7yL16IEynTp18FQcAAGgCjxN5amrqRd87/uWXX3oVEAAAzcLbW8hCpSLPyspy+XzmzBlt375d69at069+9StfxQUAgG/RWj/roYceOu/4//7v/6qoqMjrgAAAgPt89vazzMxMvfHGG746HQAAvhWi95H7LJG//vrrio2N9dXpAADwqZZ+RGteXp4GDx6s6OhoxcXFady4cdq7d6/LPoZhKCcnR0lJSYqMjNSIESO0a9cuj67jcWt94MCBLovdDMNQWVmZjh07phdeeMHT0wEAEJI2bdqkmTNnavDgwWpoaNDcuXM1evRo7d69W23btpUkLViwQAsXLtTy5cvVo0cPPfXUUxo1apT27t2r6Ohot67jcSIfN26cy+ewsDBddtllGjFihHr16uXp6QAACEnr1q1z+bxs2TLFxcWpuLhY119/vQzD0KJFizR37lyNHz9eklRQUKD4+HitWLFCv/jFL9y6jkeJvKGhQV27dtXNN9+shIQETw4FAMC/fLRqvaKiwmXYarXKarVe8vBvv/1WkpzT0CUlJSorK9Po0aNdzjV8+HBt2bLF7UTu0Rx569atdf/996uurs6TwwAA8DtfzZEnJycrJibGueXl5V3y2oZhKDs7W9dee6369u0rSSorK5MkxcfHu+wbHx/v/M4dHrfWhwwZou3btyslJcXTQwEACHqlpaWy2WzOz+5U4w888IA+//xzffTRR42+++FD1gzDuOiD137I40Q+Y8YM/fKXv9Thw4c1aNAg54T9Of379/f0lAAAtAwf3EJms9lcEvmlzJo1S2+99ZY2b96szp07O8fPTVGXlZUpMTHROV5eXt6oSr8YtxP5z372My1atEgTJkyQJD344IPO7ywWi/M3CLvd7vbFAQBoMS38ZDfDMDRr1iytXr1ahYWFSk1Ndfk+NTVVCQkJ2rhxowYOHChJqq+v16ZNmzR//ny3r+N2Ii8oKNDTTz+tkpISt08OAIBZzZw5UytWrNCbb76p6Oho57x3TEyMIiMjZbFYlJWVpdzcXKWlpSktLU25ubmKiorSxIkT3b6O24ncMM7+KsLcOAAgGLX0+8jz8/MlSSNGjHAZX7ZsmSZPnixJmj17tmpqajRjxgydPHlSQ4YM0YYNG9y+h1zycI7ck8l3AAACih9a65disViUk5OjnJycpsUkDxN5jx49LpnMv/nmmyYHAwAAPONRIn/yyScVExPTXLEAANBsWrq13lI8SuR333234uLimisWAACaT4i+j9ztJ7sxPw4AQODxeNU6AABBKUQrcrcTucPhaM44AABoVsyRAwAQzEK0Ivfo7WcAACCwUJEDAMwhRCtyEjkAwBRCdY6c1joAAEGMihwAYA601gEACF601gEAQMChIgcAmAOtdQAAgliIJnJa6wAABDEqcgCAKVi+27w5PhCRyAEA5hCirXUSOQDAFLj9DAAABBwqcgCAOdBaBwAgyAVoMvYGrXUAAIIYFTkAwBRCdbEbiRwAYA4hOkdOax0AgCBGRQ4AMAVa6wAABDNa6wAAINBQkQMATIHWOgAAwSxEW+skcgCAOYRoImeOHACAIEZFDgAwBebIAQAIZrTWAQCAuzZv3qwxY8YoKSlJFotFa9ascfl+8uTJslgsLtvQoUM9vg6JHABgChbD8HrzRFVVlQYMGKDFixdfcJ9bbrlFR48edW5r1671+OeitQ4AMIcWbq1nZmYqMzPzovtYrVYlJCR4ERQVOQAAHqmoqHDZ6urqmnyuwsJCxcXFqUePHpo2bZrKy8s9PgeJHABgCudWrXuzSVJycrJiYmKcW15eXpPiyczM1Kuvvqr3339fv/vd77Rt2zbdcMMNHv9iQGsdAGAOPmqtl5aWymazOYetVmuTTjdhwgTnf/ft21fp6elKSUnRu+++q/Hjx7t9HhI5AAAesNlsLoncVxITE5WSkqJ9+/Z5dByJHABgCoH+QJgTJ06otLRUiYmJHh1HIgcAmEMLr1qvrKzU/v37nZ9LSkq0Y8cOxcbGKjY2Vjk5ObrzzjuVmJioAwcOaM6cOerUqZPuuOMOj65DIgcAmEJLV+RFRUUaOXKk83N2drYkadKkScrPz9fOnTv18ssv69SpU0pMTNTIkSO1atUqRUdHe3QdEjkAAM1gxIgRMi7yEJn169f75DokcgCAOYTos9ZJ5AAA0wjUN5h5gwfCAAAQxKjIAQDmYBhnN2+OD0AkcgCAKQT6feRNRWsdAIAgRkUOADAHVq0DABC8LI6zmzfHByJa6wAABDEqcjQysOsR/eT6z9Tr8mO6zFatX71yszbtTnV+//h/vK/bB33hcszOQ3Gaku/+a/cAf+nw7lFFF59U+NFaOcLDVNu9nY79R2edSYxw7hP/hxLFfHzC5biabm1V+uveLR0ufInWOswiIrxB+4521NvFPbXgJxvOu8+Wvcn67ev/fobwGTvNHQSHqL2ndeqGONWmtpXshjr9+St1XviFDjx1pQxrK+d+VX1tKpvy719gjVYWf4QLH2LVejPYvHmzxowZo6SkJFksFq1Zs8af4eA7n3zRRS9uvEaFu7pdcJ8zDa10ojLKuVXURFxwXyCQfJXdQxXXdlL95ZGq7xKlr3/WVW1O1CviQLXLfkabMNlj2jg3RzvqnqB37j5yb7YA5Ne/mVVVVRowYIDuu+8+3Xnnnf4MBR66utsRrZu7XJW1Vn36ZaLyNwzRyapIf4cFeCysxi5Jsrd1/ecw8p+n1e2hHXJEtVJNz2gdH3+57LY2/ggRuCi/JvLMzExlZma6vX9dXZ3q6uqcnysqKpojLFzClr1d9NedV+joqWgldajQ9FHb9MLUt/TTxf+hM/ZWlz4BECgMQ5etKlV1WjvVd/73L6JV/WJUmd5BZzpa1eZ4nTqu/kqd/3uvDj3eR0YbppGCFa31AJCXl6eYmBjnlpyc7O+QTOkvO7vr470p+vLrWH30z656aPmt6tLpW/2o10F/hwZ4JO7/DslaWqOyX7hOI1VeE6uqAe1V3zlSVVe111f/labwsjq1/fxbP0UKnzB8sAWgoErkjz76qL799lvnVlpa6u+QIOnE6bY6eqqdunTkHzkEj8tePaS2O06pdHZPNcSGX3Rfe/twnekYrjZf17ZQdID7gmr1htVqldVq9XcY+IGYqFrFx1Tp+Okof4cCXJphKO7VQ2r36SmVPtJTDZdd+t+UsMoGtf6mXg0xzJEHs1BtrQdVIkfLiAw/o87fq66TOlQoLfG4KqqtqqiJ0LQbi/TBrlQdr4hSYofTmnHz33WqOkKFu1IvclYgMMT93yFFb/1GRx7sLkdEK7X69owkyRHZSkZ4mCy1dnV884gqB3VQQ/s2anO8Tp3e+Er26NaqvLqDn6OHV3j7Gcyi9+XlevHnbzs//9ftn0iS3inuoflrrlf3hBO69eq9io6o1/HTUSr+Mklz/jRK1fUXb08CgaD9B8ckScnz97qMl/2sqyqu7SSFWWQ9XCPblhNqVW1XQ/s2qu4VraP3XyEjksWcCDx+TeSVlZXav3+/83NJSYl27Nih2NhYdenSxY+RmdunJZfrmkenX/D7B5fd3oLRAL71xR/TL/q9ER6mr37Zo4WiQUuitd4MioqKNHLkv58Olp2dLUmaNGmSli9f7qeoAAAhiUe0+t6IESNkBOicAwAAwYA5cgCAKdBaBwAgmDmMs5s3xwcgEjkAwBxCdI48qJ7sBgAAXFGRAwBMwSIv58h9FolvkcgBAOYQok92o7UOAEAQoyIHAJgCt58BABDMWLUOAAACDRU5AMAULIYhixcL1rw5tjmRyAEA5uD4bvPm+ABEax0AgCBGRQ4AMAVa6wAABDNWrQMAEMTOPdnNm80Dmzdv1pgxY5SUlCSLxaI1a9b8IBxDOTk5SkpKUmRkpEaMGKFdu3Z5/GORyAEAaAZVVVUaMGCAFi9efN7vFyxYoIULF2rx4sXatm2bEhISNGrUKJ0+fdqj69BaBwCYgq+e7FZRUeEybrVaZbVaG+2fmZmpzMzM857LMAwtWrRIc+fO1fjx4yVJBQUFio+P14oVK/SLX/zC7bioyAEA5uCj1npycrJiYmKcW15ensehlJSUqKysTKNHj3aOWa1WDR8+XFu2bPHoXFTkAAB4oLS0VDabzfn5fNX4pZSVlUmS4uPjXcbj4+N18OBBj85FIgcAmILFcXbz5nhJstlsLoncq5gsrm85Nwyj0dil0FoHAJhDC69av5iEhARJ/67MzykvL29UpV8KiRwAgBaWmpqqhIQEbdy40TlWX1+vTZs2adiwYR6di9Y6AMAcWviBMJWVldq/f7/zc0lJiXbs2KHY2Fh16dJFWVlZys3NVVpamtLS0pSbm6uoqChNnDjRo+uQyAEAptDSj2gtKirSyJEjnZ+zs7MlSZMmTdLy5cs1e/Zs1dTUaMaMGTp58qSGDBmiDRs2KDo62qPrkMgBAGgGI0aMkHGR5G+xWJSTk6OcnByvrkMiBwCYg7cL1nhpCgAAfmTIu3eKB2YeJ5EDAMwhVF9jyu1nAAAEMSpyAIA5GPJyjtxnkfgUiRwAYA4hutiN1joAAEGMihwAYA4OSZ69j6Tx8QGIRA4AMAVWrQMAgIBDRQ4AMIcQXexGIgcAmEOIJnJa6wAABDEqcgCAOYRoRU4iBwCYA7efAQAQvLj9DAAABBwqcgCAOTBHDgBAEHMYksWLZOwIzEROax0AgCBGRQ4AMAda6wAABDMvE7kCM5HTWgcAIIhRkQMAzIHWOgAAQcxhyKv2OKvWAQCAr1GRAwDMwXCc3bw5PgCRyAEA5sAcOQAAQYw5cgAAEGioyAEA5kBrHQCAIGbIy0Tus0h8itY6AABBjIocAGAOtNYBAAhiDockL+4FdwTmfeS01gEACGIkcgCAOZxrrXuzeSAnJ0cWi8VlS0hI8PmPRWsdAGAOfpgjv/LKK/WXv/zF+blVq1ZNv/4FkMgBAGgmrVu3bpYq/PtorQMAzMFheL9JqqiocNnq6uoueMl9+/YpKSlJqampuvvuu/Xll1/6/McikQMATMEwHF5vkpScnKyYmBjnlpeXd97rDRkyRC+//LLWr1+vpUuXqqysTMOGDdOJEyd8+nPRWgcAmINhePfik+/myEtLS2Wz2ZzDVqv1vLtnZmY6/7tfv37KyMjQFVdcoYKCAmVnZzc9jh8gkQMA4AGbzeaSyN3Vtm1b9evXT/v27fNpPLTWAQDm0MK3n/1QXV2d9uzZo8TERB/9QGdRkQMAzMHhkCxePJ3N8OzYhx9+WGPGjFGXLl1UXl6up556ShUVFZo0aVLTYzgPEjkAAM3g8OHD+s///E8dP35cl112mYYOHaqtW7cqJSXFp9chkQMAzMEw5NW7SD1sra9cubLp1/IAiRwAYAqGwyHDi9a64WFrvaWw2A0AgCBGRQ4AMIcWbq23FBI5AMAcHIZkCb1ETmsdAIAgRkUOADAHw5DkzX3kgVmRk8gBAKZgOAwZXrTWDRI5AAB+ZDjkXUXO7WcAAMDHqMgBAKZAax0AgGAWoq31oE7k5347sp+p9XMkQPNx1JzxdwhAs3HUnP33uyWq3Qad8ep5MA0KzP8vWoxA7RW44fDhw0pOTvZ3GAAAL5WWlqpz587Ncu7a2lqlpqaqrKzM63MlJCSopKREERERPojMN4I6kTscDh05ckTR0dGyWCz+DscUKioqlJycrNLSUtlsNn+HA/gUf79bnmEYOn36tJKSkhQW1nzrr2tra1VfX+/1ecLDwwMqiUtB3loPCwtrtt/gcHE2m41/6BCy+PvdsmJiYpr9GhEREQGXgH2F288AAAhiJHIAAIIYiRwesVqteuKJJ2S1Wv0dCuBz/P1GMArqxW4AAJgdFTkAAEGMRA4AQBAjkQMAEMRI5AAABDESOdz2wgsvKDU1VRERERo0aJA+/PBDf4cE+MTmzZs1ZswYJSUlyWKxaM2aNf4OCXAbiRxuWbVqlbKysjR37lxt375d1113nTIzM3Xo0CF/hwZ4raqqSgMGDNDixYv9HQrgMW4/g1uGDBmiq6++Wvn5+c6x3r17a9y4ccrLy/NjZIBvWSwWrV69WuPGjfN3KIBbqMhxSfX19SouLtbo0aNdxkePHq0tW7b4KSoAgEQihxuOHz8uu92u+Ph4l/H4+HifvBYQANB0JHK47YevijUMg9fHAoCfkchxSZ06dVKrVq0aVd/l5eWNqnQAQMsikeOSwsPDNWjQIG3cuNFlfOPGjRo2bJifogIASFJrfweA4JCdna17771X6enpysjI0EsvvaRDhw5p+vTp/g4N8FplZaX279/v/FxSUqIdO3YoNjZWXbp08WNkwKVx+xnc9sILL2jBggU6evSo+vbtq2eeeUbXX3+9v8MCvFZYWKiRI0c2Gp80aZKWL1/e8gEBHiCRAwAQxJgjBwAgiJHIAQAIYiRyAACCGIkcAIAgRiIHACCIkcgBAAhiJHIAAIIYiRwAgCBGIge8lJOTo6uuusr5efLkyRo3blyLx3HgwAFZLBbt2LHjgvt07dpVixYtcvucy5cvV/v27b2OzWKxaM2aNV6fB0BjJHKEpMmTJ8tischisahNmzbq1q2bHn74YVVVVTX7tZ999lm3H+vpTvIFgIvhpSkIWbfccouWLVumM2fO6MMPP9TUqVNVVVWl/Pz8RvueOXNGbdq08cl1Y2JifHIeAHAHFTlCltVqVUJCgpKTkzVx4kTdc889zvbuuXb4H//4R3Xr1k1Wq1WGYejbb7/Vz3/+c8XFxclms+mGG27QZ5995nLep59+WvHx8YqOjtaUKVNUW1vr8v0PW+sOh0Pz589X9+7dZbVa1aVLF82bN0+SlJqaKkkaOHCgLBaLRowY4Txu2bJl6t27tyIiItSrVy+98MILLtf5+9//roEDByoiIkLp6enavn27x39GCxcuVL9+/dS2bVslJydrxowZqqysbLTfmjVr1KNHD0VERGjUqFEqLS11+f7tt9/WoEGDFBERoW7duunJJ59UQ0ODx/EA8ByJHKYRGRmpM2fOOD/v379fr732mt544w1na/u2225TWVmZ1q5dq+LiYl199dW68cYb9c0330iSXnvtNT3xxBOaN2+eioqKlJiY2CjB/tCjjz6q+fPn67HHHtPu3bu1YsUKxcfHSzqbjCXpL3/5i44ePao///nPkqSlS5dq7ty5mjdvnvbs2aPc3Fw99thjKigokCRVVVXp9ttvV8+ePVVcXKycnBw9/PDDHv+ZhIWF6bnnntM//vEPFRQU6P3339fs2bNd9qmurta8efNUUFCgjz/+WBUVFbr77rud369fv14/+clP9OCDD2r37t1asmSJli9f7vxlBUAzM4AQNGnSJGPs2LHOz3/729+Mjh07Gj/+8Y8NwzCMJ554wmjTpo1RXl7u3Oevf/2rYbPZjNraWpdzXXHFFcaSJUsMwzCMjIwMY/r06S7fDxkyxBgwYMB5r11RUWFYrVZj6dKl542zpKTEkGRs377dZTw5OdlYsWKFy9hvf/tbIyMjwzAMw1iyZIkRGxtrVFVVOb/Pz88/77m+LyUlxXjmmWcu+P1rr71mdOzY0fl52bJlhiRj69atzrE9e/YYkoy//e1vhmEYxnXXXWfk5ua6nOeVV14xEhMTnZ8lGatXr77gdQE0HXPkCFnvvPOO2rVrp4aGBp05c0Zjx47V888/7/w+JSVFl112mfNzcXGxKisr1bFjR5fz1NTU6F//+pckac+ePZo+fbrL9xkZGfrggw/OG8OePXtUV1enG2+80e24jx07ptLSUk2ZMkXTpk1zjjc0NDjn3/fs2aMBAwYoKirKJQ5PffDBB8rNzdXu3btVUVGhhoYG1dbWqqqqSm3btpUktW7dWunp6c5jevXqpfbt22vPnj265pprVFxcrG3btrlU4Ha7XbW1taqurnaJEYDvkcgRskaOHKn8/Hy1adNGSUlJjRaznUtU5zgcDiUmJqqwsLDRuZp6C1ZkZKTHxzgcDkln2+tDhgxx+a5Vq1aSJMMwmhTP9x08eFC33nqrpk+frt/+9reKjY3VRx99pClTprhMQUhnbx/7oXNjDodDTz75pMaPH99on4iICK/jBHBxJHKErLZt26p79+5u73/11VerrKxMrVu3VteuXc+7T+/evbV161b99Kc/dY5t3br1gudMS0tTZGSk/vrXv2rq1KmNvg8PD5d0toI9Jz4+Xpdffrm+/PJL3XPPPec9b58+ffTKK6+opqbG+cvCxeI4n6KiIjU0NOh3v/udwsLOLpd57bXXGu3X0NCgoqIiXXPNNZKkvXv36tSpU+rVq5eks39ue/fu9ejPGoDvkMiB79x0003KyMjQuHHjNH/+fPXs2VNHjhzR2rVrNW7cOKWnp+uhhx7SpEmTlJ6ermuvvVavvvqqdu3apW7dup33nBEREXrkkUc0e/ZshYeH60c/+pGOHTumXbt2acqUKYqLi1NkZKTWrVunzp07KyIiQjExMcrJydGDDz4om82mzMxM1dXVqaioSCdPnlR2drYmTpyouXPnasqUKfr1r3+tAwcO6H/+5388+nmvuOIKNTQ06Pnnn9eYMWP08ccf68UXX2y0X5s2bTRr1iw999xzatOmjR544AENHTrUmdgff/xx3X777UpOTtZdd92lsLAwff7559q5c6eeeuopz/+HAOARVq0D37FYLFq7dq2uv/56/exnP1OPHj10991368CBA85V5hMmTNDjjz+uRx55RIMGDdLBgwd1//33X/S8jz32mH75y1/q8ccfV+/evTVhwgSVl5dLOjv//Nxzz2nJkiVKSkrS2LFjJUlTp07V73//ey1fvlz9+vXT8OHDtXz5cuftau3atdPbb7+t3bt3a+DAgZo7d67mz5/v0c971VVXaeHChZo/f7769u2rV199VXl5eY32i4qK0iOPPKKJEycqIyNDkZGRWrlypfP7m2++We+88442btyowYMHa+jQoVq4cKFSUlI8igdA01gMX0y2AQAAv6AiBwAgiJHIAQAIYiRyAACCGIkcAIAgRiIHACCIkcgBAAhiJHIAAIIYiRwAgCBGIgcAIIiRyAEACGIkcgAAgtj/A1/SjcRAp7q2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_mod = confusion_matrix(test_true_mod, pred_cat_mod)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_mod)\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimmen Sie die Konfusionsmatrix und die Accuracy sowie für beide Klassen Precision, Recall und F1-Score. \n",
    "# Accuracy\n",
    "# True Tech + True NonTech / alles\n",
    "acc = (cm[0][0] + cm[1][1])/sum(sum(cm))\n",
    "\n",
    "# Tech\n",
    "    # Precision: True Tech / (True Tech + False Tech)\n",
    "prec_tech = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "    # Recall: True Tech / (True Tech + Flase NonTech)\n",
    "recall_tech = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_tech = 2*((prec_tech*recall_tech)/(prec_tech + recall_tech))\n",
    "\n",
    "# NonTech\n",
    "    # Precision: True NonTech / (True NonTech + False NonTech)\n",
    "prec_nonTech = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "    # Recall: True NonTech / (True NonTech + False Tech)\n",
    "recall_nonTech = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_nonTech = 2*((prec_nonTech*recall_nonTech)/(prec_nonTech + recall_nonTech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7294117647058823\n",
      "--------Tech---------\n",
      "Precision: 0.6774193548387096\n",
      "Recall: 0.9333333333333333\n",
      "F1-Score: 0.7850467289719625\n",
      "-------NonTech-------\n",
      "Precision: 0.8695652173913043\n",
      "Recall: 0.5\n",
      "F1-Score: 0.634920634920635\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc}\")\n",
    "print(\"--------Tech---------\")\n",
    "print(f\"Precision: {prec_tech}\")\n",
    "print(f\"Recall: {recall_tech}\")\n",
    "print(f\"F1-Score: {f1_tech}\")\n",
    "print(\"-------NonTech-------\")\n",
    "print(f\"Precision: {prec_nonTech}\")\n",
    "print(f\"Recall: {recall_nonTech}\")\n",
    "print(f\"F1-Score: {f1_nonTech}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Diskutieren Sie das Ergebnis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trotz der Vernachlässigung der Semantik im Dokument ergibt sich eine Accuracy von 71,76%\n",
    "* Die Precision ist für nonTech Artikel besser als für Tech, der Classifier ist bei non Tech Artikel zuverlässiger\n",
    "* Der Recall für Tech ist besser als für nonTech, Tech Artikel werden öfter erkannt als nonTech Artikel\n",
    "* Der F1-Score ist bei Kategorie Tech höher als bei nonTech. Der Classifier ist besser angepasst auf Tech Artikel\n",
    "* Die Trainings Daten habe 160 Tech Dokumente und 105 nonTech Dokumente, somit ist der Classifier besser auf Tech Dokumente trainiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wie könnte die Klassifikationsgüte durch Modifikation der *getwords()*-Methode verbessert werden? Implementieren Sie diesen Ansatz und vergleichen Sie das Ergebnis mit dem des ersten Ansatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# True Tech + True NonTech / alles\n",
    "acc_mod = (cm_mod[0][0] + cm_mod[1][1])/sum(sum(cm_mod))\n",
    "\n",
    "# Tech\n",
    "    # Precision: True Tech / (True Tech + False Tech)\n",
    "prec_tech_mod = cm_mod[0][0] / (cm_mod[0][0] + cm_mod[1][0])\n",
    "    # Recall: True Tech / (True Tech + Flase NonTech)\n",
    "recall_tech_mod = cm_mod[0][0] / (cm_mod[0][0] + cm_mod[0][1])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_tech_mod = 2*((prec_tech_mod*recall_tech_mod)/(prec_tech_mod + recall_tech_mod))\n",
    "\n",
    "# NonTech\n",
    "    # Precision: True NonTech / (True NonTech + False NonTech)\n",
    "prec_nonTech_mod = cm_mod[1][1] / (cm_mod[1][1] + cm_mod[0][1])\n",
    "    # Recall: True NonTech / (True NonTech + False Tech)\n",
    "recall_nonTech_mod = cm_mod[1][1] / (cm_mod[1][1] + cm_mod[1][0])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_nonTech_mod = 2*((prec_nonTech_mod*recall_nonTech_mod)/(prec_nonTech_mod + recall_nonTech_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.788235294117647\n",
      "--------Tech---------\n",
      "Precision: 0.7368421052631579\n",
      "Recall: 0.9333333333333333\n",
      "F1-Score: 0.8235294117647058\n",
      "-------NonTech-------\n",
      "Precision: 0.8928571428571429\n",
      "Recall: 0.625\n",
      "F1-Score: 0.7352941176470589\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc_mod}\")\n",
    "print(\"--------Tech---------\")\n",
    "print(f\"Precision: {prec_tech_mod}\")\n",
    "print(f\"Recall: {recall_tech_mod}\")\n",
    "print(f\"F1-Score: {f1_tech_mod}\")\n",
    "print(\"-------NonTech-------\")\n",
    "print(f\"Precision: {prec_nonTech_mod}\")\n",
    "print(f\"Recall: {recall_nonTech_mod}\")\n",
    "print(f\"F1-Score: {f1_nonTech_mod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsere Modefikation:\n",
    "getwordsmodified() zählt wie oft ein Wort in eine Artikel vorkommt und diese Zusatzinformation wird auch beim trainieren verwendet.\n",
    "Somit werden die Wörte nach Häufigkeit gewichtet.\n",
    "\n",
    "Durch unsere Modifikationen hat sich die Accuracy von 71% auf 75% verbessert (schwankt je nach Testdaten).\n",
    "Die Precision Werte sind bei beiden Kategorien gestiegen, der Wert bleibt jedoch höher bei der Kategorie nonTech.\n",
    "Die Recall Werte sind auch gestiegen, und auch hier bleibt der Wert für die Kategorie Tech höher (ähnlich wie bei nicht modifizierten).\n",
    "Der F1-Score erhöht sich auch bei beiden Kategorien, ist bei Tech aber höher als bei nonTech."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
