{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Document Classification\n",
    "* **Autor**: Prof. Dr. Johannes Maucher\n",
    "* **Datum**: 06.11.2015\n",
    "* **Studierende**: Paul Michels (pm080), Erzan Gashi (eg053), Patryk Gadziomski (pg058)\n",
    "\n",
    "[Übersicht Versuche im Data Mining Praktikum](http://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "## Abgabe:\n",
    "\n",
    "- **Abzugeben ist das Jupyter Notebook mit dem verlangten Implementierungen und den entsprechenden Ausgaben.**\n",
    "- **Das Notebook ist als .ipynb und als .html abzugeben.**\n",
    "- **Klausurelevante Fragen sind Dokument \"Fragenkatalog Datamining\" zu finden.**\n",
    "- Antworten auf Fragen im Notebook, Diskussionen und Beschreibung der Ergebnisse sind optional (aber empfohlen) und werden nicht bewertet.\n",
    "\n",
    "* [Übersicht Data Mining Praktikum](https://maucher.pages.mi.hdm-stuttgart.de/ai/page/dm/)\n",
    "\n",
    "\n",
    "# Einführung\n",
    "\n",
    "## Lernziele:\n",
    "\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Dokumentklassifikation: Klassifikation von Dokumenten, insbesondere Emails und RSS Feed\n",
    "* Naive Bayes Classifier: Weit verbreitete Klassifikationsmethode, welche unter bestimmten Randbedingungen sehr gut skaliert.\n",
    "\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "\n",
    "### Parametrische Klassifikation und Naive Bayes Methode\n",
    "\n",
    "Klassifikatoren müssen zu einer gegebenen Eingabe $\\underline{x}$ die zugehörige Klasse $C_i$ bestimmen. Mithilfe der Wahrscheinlichkeitstheorie kann diese Aufgabe wie folgt beschrieben werden: Bestimme für alle möglichen Klassen $C_i$ die bedingte Wahrscheinlichkeit $P(C_i | \\underline{x})$, also die Wahrscheinlichkeit, dass die gegebene Eingabe $\\underline{x}$ in Klasse $C_i$ fällt. Wähle dann die Klasse aus, für welche diese Wahrscheinlichkeit maximal ist.\n",
    "\n",
    "Die Entscheidungsregeln von Klassifikatoren können mit Methoden des \"überwachten Lernens\" aus Trainingsdaten ermittelt werden. Im Fall des **parametrischen Lernens** kann aus den Trainingsdaten die sogenannte **Likelihood-Funktion** $p(\\underline{x} \\mid C_i)$ bestimmt werden. _Anmerkung:_ Allgemein werden mit $p(...)$ kontinuierliche Wahrscheinlichkeitsfunktionen und mit $P(...)$ diskrete Wahrscheinlichkeitswerte bezeichnet. \n",
    "\n",
    "Mithilfe der **Bayes-Formel**\n",
    "$$\n",
    "P(C_i \\mid \\underline{x}) = \\frac{p(\\underline{x} \\mid C_i) \\cdot P(C_i)}{p(\\underline{x})}\n",
    "$$\n",
    "\n",
    "kann aus der Likelihood die **a-posteriori-Wahrscheinlichkeit $P(C_i \\mid \\underline{x})$** berechnet werden. Darin wird $P(C_i)$ die **a-priori-Wahrscheinlichkeit** und $p(\\underline{x})$ die **Evidenz** genannt. Die a-priori-Wahrscheinlichkeit kann ebenfalls aus den Trainingsdaten ermittelt werden. Die Evidenz ist für die Klassifikationsentscheidung nicht relevant, da sie für alle Klassen $C_i$ gleich groß ist.\n",
    "\n",
    "Die Berechnung der Likelihood-Funktion $p(\\underline{x} \\mid C_i)$ ist dann sehr aufwendig, wenn $\\underline{x}=(x_1,x_2,\\ldots,x_Z)$ ein Vektor von voneinander abhängigen Variablen $x_i$ ist. Bei der **Naive Bayes Classification** wird jedoch von der vereinfachenden Annahme ausgegangen, dass die Eingabevariabeln $x_i$ voneinander unabhängig sind. Dann vereinfacht sich die bedingte Verbundwahrscheinlichkeits-Funktion $p(x_1,x_2,\\ldots,x_Z \\mid C_i)$ zu:\n",
    "\n",
    "$$\n",
    "p(x_1,x_2,\\ldots,x_Z \\mid C_i)=\\prod\\limits_{j=1}^Z p(x_j | C_i)\n",
    "$$\n",
    "\n",
    "### Anwendung der Naive Bayes Methode in der Dokumentklassifikation\n",
    "\n",
    "Auf der rechten Seite der vorigen Gleichung stehen nur noch von den jeweils anderen Variablen unabhängige bedingte Wahrscheinlichkeiten. Im Fall der Dokumentklassifikation sind die einzelnen Worte die Variablen, d.h. ein Ausdruck der Form $P(x_j | C_i)$ gibt an mit welcher Wahrscheinlichkeit ein Wort $x_j=w$ in einem Dokument der Klasse $C_i$ vorkommt. \n",
    "Die Menge aller Variablen $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ ist dann die Menge aller Wörter im Dokument. Damit gibt die linke Seite in der oben gegebenen Gleichung die *Wahrscheinlichkeit, dass die Wörter $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ in einem Dokument der Klasse $C_i$ vorkommen*, an.\n",
    "\n",
    "Für jedes Wort _w_ wird aus den Trainingsdaten die Wahrscheinlichkeit $P(w|G)$, mit der das Wort in Dokumenten der Kategorie _Good_ und die Wahrscheinlichkeit $P(w|B)$ mit der das Wort in Dokumenten der Kategorie _Bad_ auftaucht ermittelt. Trainingsdokumente werden in der Form\n",
    "\n",
    "$$\n",
    "tD=(String,Category)\n",
    "$$\n",
    "eingegeben. \n",
    "\n",
    "Wenn \n",
    "\n",
    "* mit der Variable $fc(w,cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ in denen das Wort $w$ enthalten ist\n",
    "* mit der Variable $cc(cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ \n",
    "\n",
    "gezählt wird, dann ist \n",
    "\n",
    "$$\n",
    "P(w|G)=\\frac{fc(w,G)}{cc(G)} \\quad \\quad P(w|B)=\\frac{fc(w,B)}{cc(B)}\n",
    "$$\n",
    "\n",
    "Wird nun nach der Eingabe von $L$ Trainingsdokumenten ein neu zu klassifizierendes Dokument $D$ eingegeben und sei $W(D)$ die Menge aller Wörter in $D$, dann berechnen sich unter der Annahme, dass die Worte in $W(D)$ voneinander unabhängig sind (naive Bayes Annahme) die a-posteriori Wahrscheinlichkeiten zu:\n",
    "\n",
    "$$\n",
    "P(G|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | G) \\right) \\cdot P(G)}{p(D)}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | B) \\right) \\cdot P(B)}{p(D)}\n",
    "$$\n",
    "\n",
    "Die hierfür notwendigen a-priori-Wahrscheinlichkeiten berechnen sich zu \n",
    "\n",
    "$$\n",
    "P(G)=\\frac{cc(G)}{L}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B)=\\frac{cc(B)}{L}\n",
    "$$\n",
    "\n",
    "Die Evidenz $p(D)$ beeinflusst die Entscheidung nicht und kann deshalb ignoriert werden.\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "\n",
    "1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training für die spätere Klassifikation abgespeichert werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Naive-Bayes Classifier wird überwacht trainiert. Dabei wird ein Classifier mit den Wahrscheinlichkeiten trainiert das ein Wort w in einem Dokument der Klasse C_i vorkommt.\n",
    "\n",
    "Die Variablen cc und fc müssen abgespeichert werden:\n",
    "* cc(cat): Anzahl der Trainingsdokumente der Kategorie cat\n",
    "* fc(w,cat): Anzahl der Trainingsdokumente der Kategorie cat in denen das Wort w vorkommt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe der posteriori Wahrscheinlichkeit.\n",
    "\n",
    "Diese wird mit der Likelihood-Funktion, Evidenz und der a-priori Wahrscheinlichkeiten berechnet. \n",
    "* Likelihood-Funktion: Produkt der Wahrscheinlichkeiten dass die einzelnen Wörter aus dem Dokument in der Kategorie C_i sind.\n",
    "* a-priori Wahrscheinlichkeiten: Wahrscheinlichkeit der Kategorie C_i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tatsächlich gegeben?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annahme: Alle Eingabevektoren sind unabhängig voneinander.\n",
    "\n",
    "Nein, da Wörter in Dokumenten voneinander abhängig sind (Semantik)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Betrachten Sie die Formeln für die Berechnung von $P(G|D)$ und $P(B|D)$. Welches Problem stellt sich ein, wenn in der Menge $W(D)$ ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie $G$ vorkommt und ein anderes Wort aus $W(D)$ nicht in den Trainingsdaten der Kategorie $B$ enthalten ist? Wie könnte dieses Problem gelöst werden? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "P(w|G) bzw. P(w|B) sind 0 wenn w nich in G oder B ist, somit würde auch das Produkt in P(G|D) bzw. P(B|D) gleich 0 sein. Dadurch sind dann auch P(G|D) bzw. P(B|D) gleich 0 wodurch D mit einer Wahrscheinlichkeit von 0 in B bzw. G ist. Das Problem könnte gelöst werden wenn man eine Standard wert einführt (zb. 0.1), damit nicht durch ein einzelens Wort in einem Dokument D, das nicht in den Trainingsdaten ist, ein Dokument nicht zugewiesen werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Feature Extraction/ -Selection\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie eine Funktion *getwords(doc)*, der ein beliebiges Dokument in Form einer String-Variablen übergeben wird. In der Funktion soll der String in seine Wörter zerlegt und jedes Wort in _lowercase_ transformiert werden. Wörter, die weniger als eine untere Grenze von Zeichen (z.B. 3) oder mehr als eine obere Grenze von Zeichen (z.B. 20) enthalten, sollen ignoriert werden. Die Funktion soll ein dictionary zurückgeben, dessen _Keys_ die Wörter sind. Die _Values_ sollen für jedes Wort zunächst auf $1$ gesetzt werden.\n",
    "\n",
    "**Tipp:** Benutzen Sie für die Zerlegung des Strings und für die Darstellung aller Wörter mit ausschließlich kleinen Buchstaben die Funktionen *split(), strip('sep')* und *lower()* der Klasse *String*.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import feedparser\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(doc):\n",
    "    word_list = doc.split()\n",
    "    word_dict = {}\n",
    "    list_iligel_symbols = [\"'\",'!','?','.',',',';',':','-','_','*','+','~','#','=','}','[',']','{','(',')','/','$','€',\"\\\\\",'@','\"','%','&','“','‘', '@','’']\n",
    "    for value in word_list:\n",
    "        value_str = value.lower()\n",
    "        for sym in list_iligel_symbols:\n",
    "            value_str = value_str.replace(sym, '')\n",
    "                     \n",
    "        if(len(value_str)>=3 and len(value_str)<=20):\n",
    "            if(value_str in word_dict.keys()):\n",
    "                word_dict[value_str] = 1\n",
    "            else:\n",
    "                word_dict[value_str] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifizierte Version der Methode für die Aufgabe Klassifikation von RSS-Newsfeed\n",
    "def getwordsmodified(doc):\n",
    "    word_list = doc.split()\n",
    "    word_dict = {}\n",
    "    list_iligel_symbols = [\"'\",'!','?','.',',',';',':','-','_','*','+','~','#','=','}','[',']','{','(',')','/','$','€',\"\\\\\",'@','\"','%','&','“','‘', '@','’']\n",
    "    for value in word_list:\n",
    "        value_str = value.lower()\n",
    "        for sym in list_iligel_symbols:\n",
    "            value_str = value_str.replace(sym, '')\n",
    "                     \n",
    "        if(len(value_str)>=3 and len(value_str)<=20):\n",
    "            if(value_str in word_dict.keys()):\n",
    "                word_dict[value_str] += 1\n",
    "            else:\n",
    "                word_dict[value_str] = 1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Classifier\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie den Naive Bayes Classifier für die Dokumentklassifikation. Es bietet sich an die Funktionalität des Klassifikators und das vom Klassifikator gelernte Wissen in einer Instanz einer Klasse _Classifier_ zu kapseln. In diesem Fall kann wie folgt vorgegangen werden:\n",
    "\n",
    "* Im Konstruktor der Klasse wird je ein Dictionary für die Instanzvariablen _fc_ und _cc_ (siehe oben) initialisiert. Dabei ist _fc_ ein verschachteltes Dictionary. Seine Keys sind die bisher gelernten Worte, die Values sind wiederum Dictionaries, deren Keys die Kategorien _Good_ und _Bad_ sind und deren Values zählen wie häufig das Wort bisher in Dokumenten der jeweiligen Kategorie auftrat. Das Dictionary _cc_ hat als Keys die Kategorien _Good_ und _Bad_. Die Values zählen wie häufig Dokumente der jeweiligen Kategorien bisher auftraten.\n",
    "* Im Konstruktor wird ferner der Instanzvariablen _getfeatures_ die Funktion *getwords()* übergeben. Die Funktion _getwords()_ wurde bereits zuvor ausserhalb der Klasse definiert. Sinn dieses Vorgehens ist, dass andere Varianten um Merkmale aus Dokumenten zu extrahieren denkbar sind. Diese Varianten könnten dann ähnlich wie die *getwords()*-Funktion ausserhalb der Klasse definiert und beim Anlegen eines *Classifier*-Objekts der Instanzvariablen _getfeatures_ übergeben werden.  \n",
    "* Der Methode _incf(self,f,cat)_ wird ein Wort _f_ und die zugehörige Kategorie _cat_ des Dokuments in welchem es auftrat übergeben. In der Methode wird der *fc*-Zähler angepasst.\n",
    "* Der Methode _incc(self,cat)_ wird die Kategorie _cat_ des gerade eingelesenen Dokuments übergeben. In der Methode wird der *cc*-Zähler angepasst.\n",
    "* Die Methode _fcount(self,f,cat)_ gibt die Häufigkeit des Worts _f_ in den Dokumenten der Kategorie _cat_ zurück.\n",
    "* Die Methode _catcount(self,cat)_ gibt die Anzahl der Dokumente in der Kategorie _cat_ zurück.\n",
    "* Die Methode _totalcount(self)_ gibt die Anzahl aller Dokumente zurück.\n",
    "* Der Methode _train(self,item,cat)_ wird ein neues Trainingselement, bestehend aus der Betreffzeile (*item*) und der entsprechenden Kategorisierung (*cat*) übergeben. Der String _item_ wird mit der Instanzmethode _getfeatures_ (Diese referenziert *getwords()*) in Worte zerlegt. Für jedes einzelne Wort wird dann *incf(self,f,cat)* aufgerufen. Ausserdem wird für das neue Trainingsdokument die Methode _incc(self,cat)_ aufgerufen.\n",
    "* Die Methode _fprob(self,f,cat)_ berechnet die bedingte Wahrscheinlichkeit $P(f | cat)$ des Wortes _f_ in der Kategorie _cat_ entsprechend der oben angegebenen Formeln, indem sie den aktuellen Stand des Zählers _fc(f,cat)_ durch den aktuellen Stand des Zählers _cc(cat)_ teilt.   \n",
    "* Die Methode _fprob(self,f,cat)_ liefert evtl. ungewollt extreme Ergebnisse, wenn noch wenig Wörter im Klassifizierer verbucht sind. Kommt z.B. ein Wort erst einmal in den Trainingsdaten vor, so wird seine Auftrittswahrscheinlichkeit in der Kategorie in welcher es nicht vorkommt gleich 0 sein. Um extreme Wahrscheinlichkeitswerte im Fall noch selten vorkommender Werte zu vermeiden, soll zusätzlich zur Methode _fprob(self,f,cat)_ die Methode _weightedprob(self,f,cat)_ implementiert und angewandt werden. Der von ihr zurückgegebene Wahrscheinlichkeitswert könnte z.B. wie folgt berechnet werden:$$wprob=\\frac{initprob+count \\cdot fprob(self,f,cat)}{1+count},$$ wobei $initprob$ ein initialer Wahrscheinlichkeitswert (z.B. 0.5) ist, welcher zurückgegeben werden soll, wenn das Wort noch nicht in den Trainingsdaten aufgetaucht ist. Die Variable $count$ zählt wie oft das Wort $f$ bisher in den Trainingsdaten auftrat. Wie zu erkennen ist, nimmt der Einfluss der initialen Wahrscheinlichkeit ab, je häufiger das Wort in den Trainingsdaten auftrat.\n",
    "* Nach dem Training soll ein beliebiges neues Dokument (Text-String) eingegeben werden können. Für dieses soll mit der Methode _prob(self,item,cat)_ die a-posteriori-Wahrscheinlichkeit $P(cat|item)$ (Aufgrund der Vernachlässigung der Evidenz handelt es sich hierbei genaugenommen um das Produkt aus a-posteriori-Wahrscheinlichkeit und Evidenz), mit der das Dokument _item_ in die Kategorie _cat_ fällt berechnet werden. Innerhalb der Methode _prob(self,item,cat)_ soll zunächst die Methode _weightedprob(self,f,cat)_ für alle Wörter $f$ im Dokument _item_ aufgerufen werden. Die jeweiligen Rückgabewerte von _weightedprob(self,f,cat)_ werden multipliziert. Das Produkt der Rückgabewerte von _weightedprob(self,f,cat)_ über alle Wörter $f$ im Dokument muss schließlich noch mit der a-priori Wahrscheinlichkeit $P(G)$ bzw. $P(B)$ entsprechend der oben aufgeführten Formeln multipliziert werden. Das Resultat des Produkts wird an das aufrufende Programm zurück gegeben, die Evidenz wird also vernachlässigt (wie oben begründet).\n",
    "\n",
    "\n",
    "\n",
    "Ein Dokument _item_ wird schließlich der Kategorie _cat_ zugeteilt, für welche die Funktion _prob(self,item,cat)_ den höheren Wert zurück gibt. Da die Rückgabewerte in der Regel sehr klein sind, werden in der Regel folgende Werte angezeigt:\n",
    "* Wenn mit $g$ der Rückgabewert von _prob(self,item,cat=G)_ und mit $b$ der Rückgabewert von _prob(self,item,cat=B)_ bezeichnet wird dann ist die Wahrscheinlichkeit, dass $item$ in die Kategorie $G$ fällt, gleich:\n",
    "$$\n",
    "\\frac{g}{g+b}\n",
    "$$\n",
    "* und die Wahrscheinlichkeit, dass $item$ in die Kategorie $B$ fällt, gleich:\n",
    "$$\n",
    "\\frac{b}{g+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    categories = []\n",
    "    \n",
    "    def __init__(self, getfeatures, categories):\n",
    "        self.categories = categories\n",
    "        self.cc = {}\n",
    "        for category in self.categories:\n",
    "            self.cc[category] = 0\n",
    "        self.fc = {}\n",
    "        self.getfeatures = getfeatures\n",
    "    \n",
    "    def incf(self, cat, w, count):\n",
    "        if w in self.fc.keys():\n",
    "            if cat in self.fc[w].keys():\n",
    "                self.fc[w][cat] += count \n",
    "            else:\n",
    "                self.fc[w][cat] = count \n",
    "        elif w not in self.fc.keys():\n",
    "            self.fc[w] = {}\n",
    "            for category in self.categories:\n",
    "                self.fc[w][category] = 0\n",
    "\n",
    "            self.fc[w][cat] += count       \n",
    "\n",
    "    def incc(self, cat):\n",
    "        self.cc[cat] += 1\n",
    "\n",
    "    def fcount(self, cat, w):\n",
    "        if w in self.fc.keys():\n",
    "            x = self.fc[w][cat]\n",
    "        else:\n",
    "            x = 0\n",
    "        return x\n",
    "        \n",
    "    def catcount(self, cat):\n",
    "        return self.cc[cat]\n",
    "\n",
    "    def totalcount(self):\n",
    "        return sum(self.cc.values())\n",
    "\n",
    "    def train(self, item, cat):\n",
    "        word_dict = self.getfeatures(item)\n",
    "        for key in word_dict.keys():\n",
    "            self.incf(cat, key, word_dict[key])\n",
    "        self.incc(cat)\n",
    "    \n",
    "    def fprob(self, cat, w):\n",
    "        x = self.fcount(cat, w)/self.catcount(cat)\n",
    "        return x\n",
    "\n",
    "    def weightedprob(self, cat, w):\n",
    "        fProb = self.fprob(cat, w)\n",
    "        initProb = 0.5\n",
    "        count = 0\n",
    "        for value in self.categories:\n",
    "            count += self.fcount(value, w)\n",
    "        \n",
    "        x = (initProb + count*fProb)/ (1+count)\n",
    "        return x\n",
    "    \n",
    "    def prob(self, item, cat):\n",
    "        word_dict = self.getfeatures(item) \n",
    "        prodProb = 1\n",
    "        for value in word_dict:\n",
    "            prodProb *= self.weightedprob(cat, value)\n",
    "        catCount = self.catcount(cat)\n",
    "        totCount = self.totalcount()\n",
    "        apriori = catCount/totCount\n",
    "        x = prodProb*apriori\n",
    "        return x\n",
    "\n",
    "    def decision(self,item):\n",
    "        g = self.prob(item, self.categories[0])\n",
    "        b = self.prob(item, self.categories[1])\n",
    "        good = g/(g+b)\n",
    "        bad = b/(g+b)\n",
    "        result = ''\n",
    "        if b < g:\n",
    "            print(f\"der Text gehört mit einer Wahrscheinlichkeit von {good} zu der Kategorie '{self.categories[0]}'\")\n",
    "            result = self.categories[0]\n",
    "        else:\n",
    "            print(f\"der Text gehört mit einer Wahrscheinlichkeit von {bad} zu der Kategorie '{self.categories[1]}'\")\n",
    "            result = self.categories[1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "**Aufgabe:**\n",
    "Instanzieren Sie ein Objekt der Klasse _Classifier_ und übergeben Sie der _train()_ Methode dieser Klasse mindestens 8 kategorisierte Dokumente (Betreffzeilen als Stringvariablen zusammen mit der Kategorie Good oder Bad). Definieren Sie dann ein beliebig neues Dokument und berechnen Sie für dieses die Kategorie, in welches es mit größter Wahrscheinlichkeit fällt. Benutzen Sie für den Test das in der\n",
    "[NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/07classificationNaiveBayes.html)\n",
    "ausführlich beschriebene Beispiel zu implementieren. Berechnen Sie die Klassifikatorausgabe des Satzes _the money jumps_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/train.csv',index_col=0)\n",
    "\n",
    "data = data[data['text'].notna()]\n",
    "\n",
    "cats = []\n",
    "for value in data[\"label\"]:\n",
    "    if(value == 0):\n",
    "        cats.append(\"Good\")\n",
    "    else:\n",
    "        cats.append(\"Bad\")\n",
    "\n",
    "data[\"category\"] = cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = data.head(10000)\n",
    "category = [\"Good\", \"Bad\"]\n",
    "classifier = Classifier(getwords, category)\n",
    "classifier_mod = Classifier(getwordsmodified, category)\n",
    "\n",
    "texts = []\n",
    "cats = []\n",
    "for value in test_data[\"text\"]:\n",
    "    texts.append(value)\n",
    "\n",
    "for value in test_data[\"category\"]:\n",
    "    cats.append(value)\n",
    "\n",
    "for i in range(0,50):\n",
    "    classifier.train(texts[i], cats[i])\n",
    "\n",
    "for i in range(0,50):\n",
    "    classifier_mod.train(texts[i], cats[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7091537106296171 zu der Kategorie 'Good'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6736648675294423 zu der Kategorie 'Good'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Good'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"The money jumps.\"\n",
    "\n",
    "classifier.decision(test_string)\n",
    "classifier_mod.decision(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von RSS Newsfeeds\n",
    "Mit dem unten gegebenen Skript werden Nachrichten verschiedener Newsserver geladen und ausgegeben. Ändern Sie diese Methode ab, damit diese Strings gespeichert werden und für ein Training benutzt werden können. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used trainings samples in categorie tech 160\n",
      "Number of used trainings samples in categorie notech 112\n",
      "Number of used test samples 85\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def countFeed(feedList, title, should_print=False):\n",
    "    if should_print:\n",
    "        print(f\"--------------------News from {title}------------------------\")\n",
    "    count = 0\n",
    "    for feed in feedList:\n",
    "        if should_print:\n",
    "            print()\n",
    "            print(\"*\"*30)\n",
    "            print(feed)\n",
    "        f=feedparser.parse(feed)\n",
    "        for e in f.entries:\n",
    "            if hasattr(e, 'title') and hasattr(e, 'description'):\n",
    "                if should_print:\n",
    "                    print('\\n---------------------------')\n",
    "                fulltext=stripHTML(e.title+' '+e.description)\n",
    "                if should_print:\n",
    "                    print(fulltext)\n",
    "                count += 1\n",
    "    if should_print:\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "    return count\n",
    "\n",
    "# Unsere Funktion zum Abspeichern der Strings\n",
    "def getTextFeed(feedList, title, cat):\n",
    "    text = {}\n",
    "    for feed in feedList:\n",
    "        if(feed == 'http://rss.golem.de/rss.php?r=sw&feed=RSS0.91'):\n",
    "            cat = 'Tech'\n",
    "        elif(feed == 'http://www.welt.de/?service=Rss' or feed == 'http://newsfeed.zeit.de/politik/index'):\n",
    "            cat = 'NonTech'\n",
    "        f=feedparser.parse(feed)\n",
    "        for e in f.entries:\n",
    "            if hasattr(e, 'title') and hasattr(e, 'description'):\n",
    "                fulltext=stripHTML(e.title+' '+e.description)\n",
    "                text[fulltext] = cat\n",
    "    return text\n",
    "                \n",
    "def stripHTML(h):\n",
    "    p=''\n",
    "    s=0\n",
    "    for c in h:\n",
    "        if c=='<': \n",
    "            s=1\n",
    "        elif c=='>':\n",
    "            s=0\n",
    "            p+=' '\n",
    "        elif s==0:\n",
    "            p+=c\n",
    "    return p\n",
    "\n",
    "trainTech=['http://rss.chip.de/c/573/f/7439/index.rss',\n",
    "           #'http://feeds.feedburner.com/netzwelt',\n",
    "           'http://rss1.t-online.de/c/11/53/06/84/11530684.xml',\n",
    "           'http://www.computerbild.de/rssfeed_2261.xml?node=13',\n",
    "           'http://www.heise.de/newsticker/heise-top-atom.xml']\n",
    "\n",
    "trainNonTech=['http://newsfeed.zeit.de/index',\n",
    "              'http://newsfeed.zeit.de/wirtschaft/index',\n",
    "              'http://www.welt.de/politik/?service=Rss',\n",
    "              'http://www.spiegel.de/schlagzeilen/tops/index.rss',\n",
    "              'https://rss.sueddeutsche.de/alles',\n",
    "              'http://www.faz.net/rss/aktuell/']\n",
    "\n",
    "test=['http://rss.golem.de/rss.php?r=sw&feed=RSS0.91',\n",
    "      'http://newsfeed.zeit.de/politik/index',  \n",
    "      'http://www.welt.de/?service=Rss']\n",
    "\n",
    "countnews={}\n",
    "countnews['tech']=countFeed(trainTech, 'trainTech')\n",
    "countnews['nontech']=countFeed(trainNonTech, 'trainNonTech')\n",
    "countnews['test']=countFeed(test, 'test')\n",
    "\n",
    "print('Number of used trainings samples in categorie tech',countnews['tech'])\n",
    "print('Number of used trainings samples in categorie notech',countnews['nontech'])\n",
    "print('Number of used test samples',countnews['test'])\n",
    "print('--'*30)\n",
    "\n",
    "news_text={}\n",
    "news_text['tech'] = {}\n",
    "news_text['nontech'] = {}\n",
    "news_text['test'] = {}\n",
    "news_text['tech'] = getTextFeed(trainTech, 'trainTech', 'Tech')\n",
    "news_text['nontech'] = getTextFeed(trainNonTech, 'trainNonTech', 'NonTech')\n",
    "news_text['test'] = getTextFeed(test, 'test','')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgaben:**\n",
    "1. Trainieren Sie Ihren Naive Bayes Classifier mit allen Nachrichten der in den Listen _trainTech_ und _trainNonTech_ definierten Servern. Weisen Sie für das Training allen Nachrichten aus _trainTech_ die Kategorie _Tech_ und allen Nachrichten aus _trainNonTech_ die Kategorie _NonTech_ zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = [\"Tech\", \"NonTech\"]\n",
    "\n",
    "classifier_rss = Classifier(getwords, categories)\n",
    "classifier_rss_mod = Classifier(getwordsmodified, categories)\n",
    "\n",
    "tech_texts = []\n",
    "\n",
    "tech_texts = news_text['tech'].keys()\n",
    "nontech_texts = news_text['nontech'].keys()\n",
    "test_texts = news_text['test'].keys()\n",
    "\n",
    "for text in tech_texts:\n",
    "    classifier_rss.train(text, \"Tech\")\n",
    "for text in nontech_texts:\n",
    "    classifier_rss.train(text, \"NonTech\")\n",
    "\n",
    "for text in tech_texts:\n",
    "    classifier_rss_mod.train(text, \"Tech\")\n",
    "for text in nontech_texts:\n",
    "    classifier_rss_mod.train(text, \"NonTech\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Nach dem Training sollen alle Nachrichten aus der Liste _test_ vom Naive Bayes Classifier automatisch klassifiziert werden. Gehen Sie davon aus, dass alle Nachrichten von [http://rss.golem.de/rss.php?r=sw&feed=RSS0.91](http://rss.golem.de/rss.php?r=sw&feed=RSS0.91) tatsächlich von der Kategorie _Tech_ sind und alle Nachrichten von den beiden anderen Servern in der Liste _test_ von der Kategorie _NonTech_ sind. Bestimmen Sie die _Konfusionsmatrix_ und die _Accuracy_ sowie für beide Klassen _Precision, Recall_ und _F1-Score_. Diese Qualitätsmetriken sind z.B. in [NLP Vorlesung Document Classification](https://griesshaber.pages.mi.hdm-stuttgart.de/nlp/06classification/06classificationMetrics.html) definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7470116570895722 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8751788250716622 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8553415325242375 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8294544273775697 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5163192104775137 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8352956084750958 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9450407224894163 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5283818934056956 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5846404779895729 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8691501952019905 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9302964968707552 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6141962051293272 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8311600856291202 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7784498629353765 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.791402719335588 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5461422660641967 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8416739616776868 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8581565677568955 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6627190731166867 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5902878542120017 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7172574949127314 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.558556043593832 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9074405964721484 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6294199928899469 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6243827100030969 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5704298998296224 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.688241702452492 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7068906829060909 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7310659414368621 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7533860736063082 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5342922760167784 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7272632790076626 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.617292494304268 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8700011823722673 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8614584018460995 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5646830598038004 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9374735543585666 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8325428061713774 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.648178281771468 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5235925218022912 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5520048087021762 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7158905227479239 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6807561583943728 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8300539717902111 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8229572518158436 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8211439447183231 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9750000170358847 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6185180080127064 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.673344044398911 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8262628691253184 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9128399043084294 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6511180397131398 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8283003433378662 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9099559656549263 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8677125341968794 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5094711180452024 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7860995077225511 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7803915135776756 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9741315873574531 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8681216714135253 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.919455303749137 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.993262932341211 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.668604389986786 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.955473561099024 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9671535354372802 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8870479832539004 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9167617273696906 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9554365038117439 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9894849113929001 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7523682688383333 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.977450154774539 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9408302754459001 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.740084482058403 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9871508121377832 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.869552274690339 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5454882175876837 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9038651428551385 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.87124030448151 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8798214660046928 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9661094849711382 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9839593873096176 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9905683969674864 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9906318077842546 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9637278001637277 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.983107503618768 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7306143780347808 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9125155415322237 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9201699584631294 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9310917282991098 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5478143343509693 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.911496420697523 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9722825615523271 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5276482046128755 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6942533595021916 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9138718313899041 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9683800489416309 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5394663799217626 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.914114351951325 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8096854974525034 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7536710174672374 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7296823377751627 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8329204676867342 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8908828002576062 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6868162668968743 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6412879027619702 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9019078055218325 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5732708874981453 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9533960187311451 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5082937779002282 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5294983662178855 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7462751555655811 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8086456266884432 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7231793912168781 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6789360712879066 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7055481237839917 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5512403715623745 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8452053251757248 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7271871536797267 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9449501243850958 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9058297828682816 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6369486367389691 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9668843993821046 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8182106210107798 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7646973824829048 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6217284846385529 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6412978802833171 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.73851153667171 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8648318619266112 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9010049389697183 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8467176653974233 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8670633914950305 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9925524183983513 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.806101373308649 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6963330364803362 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9273246363956075 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9657589407872228 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7146797888712071 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8695565309157581 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.942816004434807 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9174648799027835 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.5230312291513322 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8326989173743977 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.7890746069800737 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9831224621606769 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9112923905621154 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9590763371831875 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9942106400071112 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6703799633185489 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9901793105505565 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9776186572976067 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9079129806857376 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9395469330182691 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9759271154964502 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9943839458698396 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8134250875084957 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9874585099738918 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9713540885415862 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8752209201809157 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9926782938973557 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.93453077954124 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.6000008652916976 zu der Kategorie 'Tech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9582430496632321 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.8368948782771842 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9309181521944097 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.97797114910743 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9921398091955662 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9985324831482844 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9916120354118886 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.984799404596203 zu der Kategorie 'NonTech'\n",
      "der Text gehört mit einer Wahrscheinlichkeit von 0.9824515606311323 zu der Kategorie 'NonTech'\n"
     ]
    }
   ],
   "source": [
    "pred_cat = []\n",
    "test_true = []\n",
    "pred_cat_mod = []\n",
    "test_true_mod = []\n",
    "\n",
    "for text in test_texts:\n",
    "    test_true.append(news_text['test'][text])\n",
    "    pred_cat.append(classifier_rss.decision(text))\n",
    "    \n",
    "for text in test_texts:\n",
    "    test_true_mod.append(news_text['test'][text])\n",
    "    pred_cat_mod.append(classifier_rss_mod.decision(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGwCAYAAABSAee3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyHElEQVR4nO3de1xVdb7/8fcGZAPCRtEESSQN8zKKTVbGaTIt8tI5pun8mspOaGanQkvJUs+MlpbR1HSzyJoyzTk62k1ndEqPWWKlNmnRZTImyBJTsDRBKC7uvX5/mHvOTq29WBv2Zb2ej8d6jPu71+VDY334fL7ftZbDMAxDAAAgLEUFOwAAANB8JHIAAMIYiRwAgDBGIgcAIIyRyAEACGMkcgAAwhiJHACAMBYT7ACs8Hg82rt3r5KSkuRwOIIdDgDAJMMwdPjwYaWnpysqquVqy/r6ejU2Nlo+T2xsrOLi4gIQUeCEdSLfu3evMjIygh0GAMCiiooKdenSpUXOXV9fr26Ziarc77Z8rrS0NO3atSukknlYJ/KkpCRJ0pfvnSZXIrMEiEyXn9Ev2CEALeaImvSWXvH+97wlNDY2qnK/W1/uOE2upObniprDHmUO+EKNjY0k8kA51k53JUZZ+j8HCGUxjjbBDgFoOT88JLw1pkcTkxxKTGr+dTwKzSncsE7kAAD4y2145LbwdhG34QlcMAFEIgcA2IJHhjxqfia3cmxLoh8NAEAYoyIHANiCRx5ZaY5bO7rlkMgBALbgNgy5jea3x60c25JorQMAEMaoyAEAthCpi91I5AAAW/DIkDsCEzmtdQAAwhgVOQDAFmitAwAQxli1DgAAQg4VOQDAFjw/bFaOD0UkcgCALbgtrlq3cmxLIpEDAGzBbcji288CF0sgMUcOAEAYoyIHANgCc+QAAIQxjxxyy2Hp+FBEax0AgDBGRQ4AsAWPcXSzcnwoIpEDAGzBbbG1buXYlkRrHQCAFnbffffJ4XBo6tSp3rH6+nrl5+erQ4cOSkxM1NixY1VVVWX63CRyAIAtHKvIrWzN8e677+qpp55Sdna2z/i0adO0Zs0avfDCCyouLtbevXs1ZswY0+cnkQMAbMFjOCxvklRTU+OzNTQ0nPSatbW1GjdunJ5++mm1b9/eO15dXa1FixbpoYce0kUXXaQBAwZo8eLF2rJli7Zt22bq5yKRAwBgQkZGhpKTk71bYWHhSffNz8/Xv//7vys3N9dnfMeOHWpqavIZ79Wrl7p27aqtW7eaiofFbgAAWwjUYreKigq5XC7vuNPpPOH+K1as0Hvvvad33333uO8qKysVGxurdu3a+YynpqaqsrLSVFwkcgCALbgVJbeFRrT7h/91uVw+ifxEKioqdOutt2rDhg2Ki4tr9jX9QWsdAGALhsX5ccPwv5rfsWOH9u/fr7POOksxMTGKiYlRcXGxFixYoJiYGKWmpqqxsVGHDh3yOa6qqkppaWmmfi4qcgAAAuziiy/WRx995DM2YcIE9erVSzNmzFBGRobatGmjjRs3auzYsZKk0tJS7d69Wzk5OaauRSIHANhCaz4QJikpSX379vUZa9u2rTp06OAdnzhxogoKCpSSkiKXy6UpU6YoJydH5513nqm4SOQAAFtwG1FyGxbmyAP8iNaHH35YUVFRGjt2rBoaGjRs2DA98cQTps9DIgcAoBVs2rTJ53NcXJyKiopUVFRk6bwkcgCALXjkkMfCGm+PQvOtKSRyAIAt8NIUAAAQcqjIAQC2YH2xG611AACC5ugcefPb41aObUm01gEACGNU5AAAW/BYfNY6q9YBAAgi5sgBAAhjHkVF5H3kzJEDABDGqMgBALbgNhxym3gV6YmOD0UkcgCALbgtLnZz01oHAACBRkUOALAFjxElj4VV6x5WrQMAEDy01gEAQMihIgcA2IJH1laeewIXSkCRyAEAtmD9gTCh2cQOzagAAIBfqMgBALZg/VnroVn7ksgBALYQqe8jJ5EDAGwhUivy0IwKAAD4hYocAGAL1h8IE5q1L4kcAGALHsMhj5X7yEP07Weh+esFAADwCxU5AMAWPBZb66H6QBgSOQDAFqy//Sw0E3loRgUAAPxCRQ4AsAW3HHJbeKiLlWNbEokcAGALtNYBAEDIoSIHANiCW9ba4+7AhRJQJHIAgC3QWgcAIIwde2mKlc2MhQsXKjs7Wy6XSy6XSzk5OXr11Ve93w8ePFgOh8Nnu/HGG03/XFTkAAC0gC5duui+++5Tjx49ZBiGnnvuOY0aNUrvv/++fvGLX0iSJk2apHnz5nmPSUhIMH0dEjkAwBYMi+8jN344tqamxmfc6XTK6XQet//IkSN9Ps+fP18LFy7Utm3bvIk8ISFBaWlpzY5JorUOALCJQLXWMzIylJyc7N0KCwt//tput1asWKG6ujrl5OR4x5ctW6aOHTuqb9++mjVrlr777jvTPxcVOQAAJlRUVMjlcnk/n6gaP+ajjz5STk6O6uvrlZiYqFWrVqlPnz6SpKuvvlqZmZlKT0/Xhx9+qBkzZqi0tFQvv/yyqXhI5AAAWwjUa0yPLV7zR8+ePVVSUqLq6mq9+OKLysvLU3Fxsfr06aMbbrjBu1+/fv3UuXNnXXzxxSovL9fpp5/ud1wkcgCALbgtvv2sOcfGxsYqKytLkjRgwAC9++67evTRR/XUU08dt+/AgQMlSWVlZaYSOXPkAAC0Eo/Ho4aGhhN+V1JSIknq3LmzqXNSkQMAbCFQrXV/zZo1SyNGjFDXrl11+PBhLV++XJs2bdL69etVXl6u5cuX69JLL1WHDh304Ycfatq0aRo0aJCys7NNXYdEDgCwBY+i5LHQiDZ77P79+3Xttddq3759Sk5OVnZ2ttavX69LLrlEFRUVeu211/TII4+orq5OGRkZGjt2rH73u9+ZjotEDgBAC1i0aNFJv8vIyFBxcXFArkMiBwDYgttwyG2htW7l2JZEIgcA2EJrz5G3FhI5AMAWDItvPzN4+xkAAAg0KnIAgC245ZDbwktTrBzbkkjkAABb8BjW5rk9RgCDCSBa6wAAhDEqcvyklY910rOF6Rp9/de6ad5XkqRH7+ii999M0oGqNopP8Kj32XWa+Nu96trjxI8dBELdbyZX6fxLq5WR1aDG+ih9sj1Bi+Z31p7yuGCHhgDyWFzsZuXYlkQix0mVlsTrb//TQd36fO8z3iP7e1005ludcmqTDn8brf95ME3/fdXpeu6dTxQdHaRgAQuyc+q0ZklH/bMkQdExhsbP3Kd7//y5Jl3YUw3f85c6UnjkkMfCPLeVY1tSSPx6UVRUpNNOO01xcXEaOHCg/v73vwc7JNv7vi5Kv5+cqakPVCgp2e3z3aXXHFC/8+qUltGoHtnfK2/GPn29N1ZVFbFBihaw5rfjumvD8yn68p9x+vyTeD04tatSuzSpR/b3P38wEGRBT+QrV65UQUGB7rzzTr333nvq37+/hg0bpv379wc7NFt7/L+76NyLa3TWoNqf3K/+uyj978oUpXVt0CnpTa0UHdCy2rqO/vJ6+BDVeCQ59mQ3K1soCnoif+ihhzRp0iRNmDBBffr00ZNPPqmEhAQ9++yzwQ7Ntjatbqeyj+J13ax9J91nzZIOGpXVT6OysvXu6y4VrihXm9gQXdIJmOBwGLpx7lf6+O8J+rI0PtjhIICOzZFb2UJRUKNqbGzUjh07lJub6x2LiopSbm6utm7detz+DQ0Nqqmp8dkQWPu/aqOFc07VjMe/VGzcyRPzRWO+1RP/W6o/vPyZunRv0Pz/Ok2N9aH52ypgxuR7v1Jmr3oV3pQZ7FAAvwR1sds333wjt9ut1NRUn/HU1FR9+umnx+1fWFiouXPntlZ4tlT2YYIOfdNG+cN6esc8boc+2tZWf13cUWu/+EDR0VJbl0dtXY06tXujep31hcb27qu3X03WkMsPBS94wKL8+Xs08JIa3Xb56fpmH2s+Io1HFp+1HqKL3cJq1fqsWbNUUFDg/VxTU6OMjIwgRhR5zrzgsJ563feXqAendVVGVr2uyN9/wlXphiHJcKipMTTbTsDPM5Q//yv92/Bq3f7rLFVVOIMdEFqAYXHVukEiP17Hjh0VHR2tqqoqn/GqqiqlpaUdt7/T6ZTTyb9gLSkh0aPTetX7jMUleJTU3q3TetVr35exKv5rOw248LCSU47o631t9PzjqYqN9+jci5nqQHiafO9XGnL5t7prQjd9Xxul9qccXbhZdzhajfX8ghopePtZC4iNjdWAAQO0ceNGjR49WpLk8Xi0ceNGTZ48OZih4SRinR59/E6iVj19imqro9Wu4xH1O69WD//lM7XreCTY4QHNMnL8AUnSH14u9xn/w9QMbXg+JRghAX4Lemu9oKBAeXl5Ovvss3XuuefqkUceUV1dnSZMmBDs0PCDB14q8/65Q9oR3fM/nwcxGiDwhqX3D3YIaAU82a2F/OY3v9HXX3+tOXPmqLKyUmeeeabWrVt33AI4AACsoLXegiZPnkwrHQCAZgiJRA4AQEuL1Getk8gBALYQqa310Jy5BwAAfqEiBwDYQqRW5CRyAIAtRGoip7UOAEAYoyIHANhCpFbkJHIAgC0YsnYL2clf7BxcJHIAgC1EakXOHDkAAGGMihwAYAuRWpGTyAEAthCpiZzWOgAAYYyKHABgC1TkAACEMcNwWN7MWLhwobKzs+VyueRyuZSTk6NXX33V+319fb3y8/PVoUMHJSYmauzYsaqqqjL9c5HIAQBoAV26dNF9992nHTt2aPv27brooos0atQo/eMf/5AkTZs2TWvWrNELL7yg4uJi7d27V2PGjDF9HVrrAABbCNT7yGtqanzGnU6nnE7ncfuPHDnS5/P8+fO1cOFCbdu2TV26dNGiRYu0fPlyXXTRRZKkxYsXq3fv3tq2bZvOO+88v+OiIgcA2MKxOXIrmyRlZGQoOTnZuxUWFv7std1ut1asWKG6ujrl5ORox44dampqUm5urnefXr16qWvXrtq6daupn4uKHAAAEyoqKuRyubyfT1SNH/PRRx8pJydH9fX1SkxM1KpVq9SnTx+VlJQoNjZW7dq189k/NTVVlZWVpuIhkQMAbKE5C9Z+fLwk7+I1f/Ts2VMlJSWqrq7Wiy++qLy8PBUXFzc7hhMhkQMAbCEYt5/FxsYqKytLkjRgwAC9++67evTRR/Wb3/xGjY2NOnTokE9VXlVVpbS0NFPXYI4cAGALrX372Yl4PB41NDRowIABatOmjTZu3Oj9rrS0VLt371ZOTo6pc1KRAwDQAmbNmqURI0aoa9euOnz4sJYvX65NmzZp/fr1Sk5O1sSJE1VQUKCUlBS5XC5NmTJFOTk5plasSyRyAIBNGBZb62Yr8v379+vaa6/Vvn37lJycrOzsbK1fv16XXHKJJOnhhx9WVFSUxo4dq4aGBg0bNkxPPPGE6bhI5AAAWzAkGYa1481YtGjRT34fFxenoqIiFRUVNT8oMUcOAEBYoyIHANiCRw45AvBkt1BDIgcA2EKg7iMPNbTWAQAIY1TkAABb8BgOOSLwfeQkcgCALRiGxVXrFo5tSbTWAQAIY1TkAABbiNTFbiRyAIAtkMgBAAhjkbrYjTlyAADCGBU5AMAWInXVOokcAGALRxO5lTnyAAYTQLTWAQAIY1TkAABbYNU6AABhzJD5d4r/+PhQRGsdAIAwRkUOALAFWusAAISzCO2tk8gBAPZgsSJXiFbkzJEDABDGqMgBALbAk90AAAhjkbrYjdY6AABhjIocAGAPhsPagrUQrchJ5AAAW4jUOXJa6wAAhDEqcgCAPfBAGAAAwlekrlr3K5H/9a9/9fuEl112WbODAQAA5viVyEePHu3XyRwOh9xut5V4AABoOSHaHrfCr0Tu8XhaOg4AAFpUpLbWLa1ar6+vD1QcAAC0LCMAWwgyncjdbrfuvvtunXrqqUpMTNTnn38uSZo9e7YWLVoU8AABAMDJmU7k8+fP15IlS3T//fcrNjbWO963b18988wzAQ0OAIDAcQRg819hYaHOOeccJSUlqVOnTho9erRKS0t99hk8eLAcDofPduONN5q6julEvnTpUv3xj3/UuHHjFB0d7R3v37+/Pv30U7OnAwCgdbRya724uFj5+fnatm2bNmzYoKamJg0dOlR1dXU++02aNEn79u3zbvfff7+p65i+j/yrr75SVlbWceMej0dNTU1mTwcAQFipqanx+ex0OuV0Oo/bb926dT6flyxZok6dOmnHjh0aNGiQdzwhIUFpaWnNjsd0Rd6nTx+9+eabx42/+OKL+uUvf9nsQAAAaFEBqsgzMjKUnJzs3QoLC/26fHV1tSQpJSXFZ3zZsmXq2LGj+vbtq1mzZum7774z9WOZrsjnzJmjvLw8ffXVV/J4PHr55ZdVWlqqpUuXau3atWZPBwBA6wjQ288qKirkcrm8wyeqxn/M4/Fo6tSpOv/889W3b1/v+NVXX63MzEylp6frww8/1IwZM1RaWqqXX37Z77BMJ/JRo0ZpzZo1mjdvntq2bas5c+borLPO0po1a3TJJZeYPR0AAGHF5XL5JHJ/5Ofn6+OPP9Zbb73lM37DDTd4/9yvXz917txZF198scrLy3X66af7de5mPWv9ggsu0IYNG5pzKAAAQRGs15hOnjxZa9eu1ebNm9WlS5ef3HfgwIGSpLKyspZN5JK0fft27dy5U9LRefMBAwY091QAALS8Vn77mWEYmjJlilatWqVNmzapW7duP3tMSUmJJKlz585+X8d0It+zZ4+uuuoqvf3222rXrp0k6dChQ/q3f/s3rVix4md/2wAAwA7y8/O1fPly/eUvf1FSUpIqKyslScnJyYqPj1d5ebmWL1+uSy+9VB06dNCHH36oadOmadCgQcrOzvb7OqZXrV9//fVqamrSzp07dfDgQR08eFA7d+6Ux+PR9ddfb/Z0AAC0jmOL3axsJixcuFDV1dUaPHiwOnfu7N1WrlwpSYqNjdVrr72moUOHqlevXrrttts0duxYrVmzxtR1TFfkxcXF2rJli3r27Okd69mzpx577DFdcMEFZk8HAECrcBhHNyvHm2H8zKR6RkaGiouLmx/QD0wn8oyMjBM++MXtdis9Pd1yQAAAtIhWniNvLaZb6w888ICmTJmi7du3e8e2b9+uW2+9VX/4wx8CGhwAAPhpflXk7du3l8Pxr7mBuro6DRw4UDExRw8/cuSIYmJidN1112n06NEtEigAAJYE6IEwocavRP7II4+0cBgAALSwCG2t+5XI8/LyWjoOAADQDM1+IIwk1dfXq7Gx0WfM7GPrAABoFRFakZte7FZXV6fJkyerU6dOatu2rdq3b++zAQAQklr5feStxXQiv+OOO/T6669r4cKFcjqdeuaZZzR37lylp6dr6dKlLREjAAA4CdOt9TVr1mjp0qUaPHiwJkyYoAsuuEBZWVnKzMzUsmXLNG7cuJaIEwAAayJ01brpivzgwYPq3r27pKPz4QcPHpQk/epXv9LmzZsDGx0AAAFy7MluVrZQZDqRd+/eXbt27ZIk9erVS88//7yko5X6sZeoAACA1mE6kU+YMEEffPCBJGnmzJkqKipSXFycpk2bpttvvz3gAQIAEBARutjN9Bz5tGnTvH/Ozc3Vp59+qh07digrK8vUa9cAAIB1lu4jl6TMzExlZmYGIhYAAFqMQxbffhawSALLr0S+YMECv094yy23NDsYAABgjl+J/OGHH/brZA6HIyiJ/LKJ1ygmJq7Vrwu0hsb13wY7BKDFHKlrkC5vpYtF6O1nfiXyY6vUAQAIWzyiFQAAhBrLi90AAAgLEVqRk8gBALZg9elsEfNkNwAAEDqoyAEA9hChrfVmVeRvvvmmrrnmGuXk5Oirr76SJP3pT3/SW2+9FdDgAAAImAh9RKvpRP7SSy9p2LBhio+P1/vvv6+GhgZJUnV1te69996ABwgAAE7OdCK/55579OSTT+rpp59WmzZtvOPnn3++3nvvvYAGBwBAoETqa0xNz5GXlpZq0KBBx40nJyfr0KFDgYgJAIDAi9Anu5muyNPS0lRWVnbc+FtvvaXu3bsHJCgAAAKOOfKjJk2apFtvvVXvvPOOHA6H9u7dq2XLlmn69Om66aabWiJGAABwEqZb6zNnzpTH49HFF1+s7777ToMGDZLT6dT06dM1ZcqUlogRAADLIvWBMKYTucPh0G9/+1vdfvvtKisrU21trfr06aPExMSWiA8AgMCI0PvIm/1AmNjYWPXp0yeQsQAAAJNMJ/IhQ4bI4Tj5yr3XX3/dUkAAALQIq7eQRUpFfuaZZ/p8bmpqUklJiT7++GPl5eUFKi4AAAKL1vpRDz/88AnH77rrLtXW1loOCAAA+C9gbz+75ppr9OyzzwbqdAAABFYr30deWFioc845R0lJSerUqZNGjx6t0tJSn33q6+uVn5+vDh06KDExUWPHjlVVVZWp6wQskW/dulVxcXGBOh0AAAHV2o9oLS4uVn5+vrZt26YNGzaoqalJQ4cOVV1dnXefadOmac2aNXrhhRdUXFysvXv3asyYMaauY7q1/uMLGIahffv2afv27Zo9e7bZ0wEAEFZqamp8PjudTjmdzuP2W7dunc/nJUuWqFOnTtqxY4cGDRqk6upqLVq0SMuXL9dFF10kSVq8eLF69+6tbdu26bzzzvMrHtMVeXJyss+WkpKiwYMH65VXXtGdd95p9nQAAISVjIwMnzxYWFjo13HV1dWSpJSUFEnSjh071NTUpNzcXO8+vXr1UteuXbV161a/4zFVkbvdbk2YMEH9+vVT+/btzRwKAEBwBWjVekVFhVwul3f4RNX4j3k8Hk2dOlXnn3+++vbtK0mqrKxUbGys2rVr57NvamqqKisr/Q7LVCKPjo7W0KFDtXPnThI5ACCsBOoRrS6XyyeR+yM/P18ff/yx3nrrreYHcBKmW+t9+/bV559/HvBAAACIRJMnT9batWv1xhtvqEuXLt7xtLQ0NTY2HvcK8KqqKqWlpfl9ftOJ/J577tH06dO1du1a7du3TzU1NT4bAAAhqxVfYWoYhiZPnqxVq1bp9ddfV7du3Xy+HzBggNq0aaONGzd6x0pLS7V7927l5OT4fR2/W+vz5s3TbbfdpksvvVSSdNlll/k8qtUwDDkcDrndbr8vDgBAq2nlJ7vl5+dr+fLl+stf/qKkpCTvvHdycrLi4+OVnJysiRMnqqCgQCkpKXK5XJoyZYpycnL8XrEumUjkc+fO1Y033qg33njD3E8CAIANLVy4UJI0ePBgn/HFixdr/Pjxko4+LTUqKkpjx45VQ0ODhg0bpieeeMLUdfxO5IZx9FeRCy+80NQFAAAIBa39PvJjefOnxMXFqaioSEVFRc2MyuSq9Z966xkAACGNl6ZIZ5xxxs8m84MHD1oKCAAA+M9UIp87d66Sk5NbKhYAAFpMa7fWW4upRH7llVeqU6dOLRULAAAtJ0Jb637fR878OAAAocf0qnUAAMJShFbkfidyj8fTknEAANCimCMHACCcRWhFbvpZ6wAAIHRQkQMA7CFCK3ISOQDAFiJ1jpzWOgAAYYyKHABgD7TWAQAIX7TWAQBAyKEiBwDYA611AADCWIQmclrrAACEMSpyAIAtOH7YrBwfikjkAAB7iNDWOokcAGAL3H4GAABCDhU5AMAeaK0DABDmQjQZW0FrHQCAMEZFDgCwhUhd7EYiBwDYQ4TOkdNaBwAgjFGRAwBsgdY6AADhjNY6AAAINVTkAABboLUOAEA4i9DWOokcAGAPEZrImSMHAKAFbN68WSNHjlR6erocDodWr17t8/348ePlcDh8tuHDh5u+DokcAGALx+bIrWxm1NXVqX///ioqKjrpPsOHD9e+ffu825///GfTPxetdQCAPbRya33EiBEaMWLET+7jdDqVlpZmISgqcgAATKmpqfHZGhoamn2uTZs2qVOnTurZs6duuukmHThwwPQ5SOQAAFtwGIblTZIyMjKUnJzs3QoLC5sVz/Dhw7V06VJt3LhRv//971VcXKwRI0bI7XabOg+tdQCAPQSotV5RUSGXy+UddjqdzTrdlVde6f1zv379lJ2drdNPP12bNm3SxRdf7Pd5qMgBADDB5XL5bM1N5D/WvXt3dezYUWVlZaaOoyIHANhCqD/Zbc+ePTpw4IA6d+5s6jgSOQDAHlp51Xptba1Pdb1r1y6VlJQoJSVFKSkpmjt3rsaOHau0tDSVl5frjjvuUFZWloYNG2bqOiRyAABawPbt2zVkyBDv54KCAklSXl6eFi5cqA8//FDPPfecDh06pPT0dA0dOlR333236VY9iRwAYAut3VofPHiwDOPkB61fv775wfwfJHIAgD1E6LPWSeQAAFsI9cVuzcXtZwAAhDEqcgCAPdBaBwAgvIVqe9wKWusAAIQxKnIAgD0YxtHNyvEhiEQOALAFVq0DAICQQ0UOALAHVq0DABC+HJ6jm5XjQxGtdQAAwhgVOY7Tr1elrviPj9Wj2zfq2P57zXnoIm3Znvl/9jCU9+v3demQfyqxbaP+8c9OevTZHH1VmRy0mAEzotfUKOZvNXJUHZEkGZmxahrXTp5zEo7u0OhRmz8eVPSmOqnJkGdAvBqndJTaRwcvaFgXoa11KnIcJ855RJ9/2V6PLc454fe/GfmRLh+2U48+m6PJs/9D9fUxum/m/6pNmyOtHCnQPMYpMWq6LkUNj5+qhsdOlbt/nGLvqpLji0ZJUpsnDypq23dq/F0nNfyhsxwH3YqdVxXkqGHVsVXrVrZQFNREvnnzZo0cOVLp6elyOBxavXp1MMPBD979oIsWvzBAb/tU4ccYGjP8Ey1bna0tOzK1qyJFv184SB3afa/zz97d6rECzeE5L0GecxNknNpGRpc2OjIhRYqLUtSnDVKdR9HrD6vpvzrIc2a8jB5ONRZ0VPQnDXLsrA926LDi2H3kVrYQFNREXldXp/79+6uoqCiYYcCEzp1q1aH993rv43TvWN33sdpZ3lF9euwPYmRAM7kNRW+qlRo88vR2KuqzBjmOSJ5fxnl3MbrGytMpWlE7G4IXJ3ASQZ0jHzFihEaMGOH3/g0NDWpo+Ne/SDU1NS0RFn5C++TvJEnfVsf7jB+qjldK8vfBCAloFseuRjmn7pUaDSk+So1zUmVkxiqqvFZGG0mJP5oPbxctx0F3UGJFYPBAmBBQWFio5ORk75aRkRHskACEKaNLGzU8caoaFqTryH8kKfYPX8vxZWOww0JLMgKwhaCwSuSzZs1SdXW1d6uoqAh2SLbzbfXRVb3tf1R9t0v+Xgd/VKUDIa2N4+gceQ+njlyXIk+3WMWsrpGREi1Hk6TaH1Xfh9wyUli1jtATVonc6XTK5XL5bGhd+/Yn6sC38frlL/Z5xxLiG9X79G/0yWedghgZYJGho7ea9XDKiJGi3v/XwjZHRaOi9rvl6e0MXnywLFJXrXMfOY4T52zSqWn/Wn/Q+ZRanZ55QIdrndp/IFEvr+ujcZd/oK8qXar8OlHj/9/7OnAoXm9v7xrEqAH/xTx7UJ5z4mWcEiN9byj6jVpFfVivxvlpUtsouYclqc0fD6gpKUpG2yi1KTogd2+njN5xP39yhC7efga76Nn9Gz04e533803/+XdJ0vriLD3w1AVauaaf4pxHNO36LUpMaNTH/+ykmfcNVVMTf50QHhyH3GrzwDdyHDwiJUTJ0y1WjfPT5BlwdHqo6cYUtYmSYu/ef7RKPztejZM7BDlq4MSC+l/e2tpalZWVeT/v2rVLJSUlSklJUdeuVHfB8sHOzsq9esJP7OHQcy+epedePKvVYgICqanglJ/eITZKTZM7qmlyx9YJCK0iUletBzWRb9++XUOGDPF+LigokCTl5eVpyZIlQYoKABCRIvQRrUFN5IMHD5YRonMOAACEAyY1AQC2QGsdAIBw5jGOblaOD0EkcgCAPUToHHlYPRAGAAD4oiIHANiCQxbnyAMWSWCRyAEA9hChT3ajtQ4AQBijIgcA2AK3nwEAEM5YtQ4AAPy1efNmjRw5Uunp6XI4HFq9erXP94ZhaM6cOercubPi4+OVm5urzz77zPR1SOQAAFtwGIblzYy6ujr1799fRUVFJ/z+/vvv14IFC/Tkk0/qnXfeUdu2bTVs2DDV19ebug6tdQCAPXh+2Kwcb8KIESM0YsSIE35nGIYeeeQR/e53v9OoUaMkSUuXLlVqaqpWr16tK6+80u/rUJEDAGBCTU2Nz9bQ0GD6HLt27VJlZaVyc3O9Y8nJyRo4cKC2bt1q6lwkcgCALQSqtZ6RkaHk5GTvVlhYaDqWyspKSVJqaqrPeGpqqvc7f9FaBwDYQ4BWrVdUVMjlcnmHnU6npbCsoiIHANjDsSe7WdkkuVwun605iTwtLU2SVFVV5TNeVVXl/c5fJHIAAFpZt27dlJaWpo0bN3rHampq9M477ygnJ8fUuWitAwBsobWf7FZbW6uysjLv5127dqmkpEQpKSnq2rWrpk6dqnvuuUc9evRQt27dNHv2bKWnp2v06NGmrkMiBwDYQyu/NGX79u0aMmSI93NBQYEkKS8vT0uWLNEdd9yhuro63XDDDTp06JB+9atfad26dYqLizN1HRI5AAAtYPDgwTJ+Ivk7HA7NmzdP8+bNs3QdEjkAwBYcnqObleNDEYkcAGAPvI8cAACEGipyAIA9ROhrTEnkAABbaM4bzH58fCiitQ4AQBijIgcA2EOELnYjkQMA7MGQtfeRh2YeJ5EDAOyBOXIAABByqMgBAPZgyOIcecAiCSgSOQDAHiJ0sRutdQAAwhgVOQDAHjySHBaPD0EkcgCALbBqHQAAhBwqcgCAPUToYjcSOQDAHiI0kdNaBwAgjFGRAwDsIUIrchI5AMAeuP0MAIDwxe1nAAAg5FCRAwDsgTlyAADCmMeQHBaSsSc0EzmtdQAAwhgVOQDAHmitAwAQziwmcoVmIqe1DgBAGKMiBwDYA611AADCmMeQpfY4q9YBAECgUZEDAOzB8BzdrBwfgkjkAAB7iNA5clrrAAB78BjWNxPuuusuORwOn61Xr14B/7GoyAEAaCG/+MUv9Nprr3k/x8QEPu2SyAEA9hCE1npMTIzS0tKaf00/0FoHANiDoX8l82ZtR09TU1PjszU0NJz0kp999pnS09PVvXt3jRs3Trt37w74j0UiBwDAhIyMDCUnJ3u3wsLCE+43cOBALVmyROvWrdPChQu1a9cuXXDBBTp8+HBA46G1DgCwhwC11isqKuRyubzDTqfzhLuPGDHC++fs7GwNHDhQmZmZev755zVx4sTmx/EjJHIAgD14PJIs3AvuOXqsy+XySeT+ateunc444wyVlZU1P4YToLUOAEArqK2tVXl5uTp37hzQ85LIAQD2YGmhm/m2/PTp01VcXKwvvvhCW7Zs0eWXX67o6GhdddVVAf2xaK0DAOyhlW8/27Nnj6666iodOHBAp5xyin71q19p27ZtOuWUU5ofwwmQyAEAaAErVqxoleuQyAEA9hChrzElkQMAbMEwPDIsvMHMyrEtiUQOALAHw/yLT447PgSxah0AgDBGRQ4AsAfD4hx5iFbkJHIAgD14PJLDwjx3iM6R01oHACCMUZEDAOyB1joAAOHL8HhkWGith+rtZ7TWAQAIY1TkAAB7oLUOAEAY8xiSI/ISOa11AADCGBU5AMAeDEOSlfvIQ7MiJ5EDAGzB8BgyLLTWDRI5AABBZHhkrSLn9jMAABBgVOQAAFugtQ4AQDiL0NZ6WCfyY78dHTnSEORIgJZzpI6/34hcR747+ve7NardI2qy9DyYI2oKXDAB5DBCtVfghz179igjIyPYYQAALKqoqFCXLl1a5Nz19fXq1q2bKisrLZ8rLS1Nu3btUlxcXAAiC4ywTuQej0d79+5VUlKSHA5HsMOxhZqaGmVkZKiiokIulyvY4QABxd/v1mcYhg4fPqz09HRFRbXc+uv6+no1NjZaPk9sbGxIJXEpzFvrUVFRLfYbHH6ay+XiP3SIWPz9bl3Jycktfo24uLiQS8CBwu1nAACEMRI5AABhjEQOU5xOp+688045nc5ghwIEHH+/EY7CerEbAAB2R0UOAEAYI5EDABDGSOQAAIQxEjkAAGGMRA6/FRUV6bTTTlNcXJwGDhyov//978EOCQiIzZs3a+TIkUpPT5fD4dDq1auDHRLgNxI5/LJy5UoVFBTozjvv1Hvvvaf+/ftr2LBh2r9/f7BDAyyrq6tT//79VVRUFOxQANO4/Qx+GThwoM455xw9/vjjko4+5z4jI0NTpkzRzJkzgxwdEDgOh0OrVq3S6NGjgx0K4BcqcvysxsZG7dixQ7m5ud6xqKgo5ebmauvWrUGMDABAIsfP+uabb+R2u5WamuoznpqaGpDXAgIAmo9EDgBAGCOR42d17NhR0dHRqqqq8hmvqqpSWlpakKICAEgkcvghNjZWAwYM0MaNG71jHo9HGzduVE5OThAjAwDEBDsAhIeCggLl5eXp7LPP1rnnnqtHHnlEdXV1mjBhQrBDAyyrra1VWVmZ9/OuXbtUUlKilJQUde3aNYiRAT+P28/gt8cff1wPPPCAKisrdeaZZ2rBggUaOHBgsMMCLNu0aZOGDBly3HheXp6WLFnS+gEBJpDIAQAIY8yRAwAQxkjkAACEMRI5AABhjEQOAEAYI5EDABDGSOQAAIQxEjkAAGGMRA4AQBgjkQMWjR8/XqNHj/Z+Hjx4sKZOndrqcWzatEkOh0OHDh066T4Oh0OrV6/2+5x33XWXzjzzTEtxffHFF3I4HCopKbF0HgAnRiJHRBo/frwcDoccDodiY2OVlZWlefPm6ciRIy1+7Zdffll33323X/v6k3wB4Kfw0hRErOHDh2vx4sVqaGjQK6+8ovz8fLVp00azZs06bt/GxkbFxsYG5LopKSkBOQ8A+IOKHBHL6XQqLS1NmZmZuummm5Sbm6u//vWvkv7VDp8/f77S09PVs2dPSVJFRYWuuOIKtWvXTikpKRo1apS++OIL7zndbrcKCgrUrl07dejQQXfccYd+/LqCH7fWGxoaNGPGDGVkZMjpdCorK0uLFi3SF1984X1RR/v27eVwODR+/HhJR18TW1hYqG7duik+Pl79+/fXiy++6HOdV155RWeccYbi4+M1ZMgQnzj9NWPGDJ1xxhlKSEhQ9+7dNXv2bDU1NR2331NPPaWMjAwlJCToiiuuUHV1tc/3zzzzjHr37q24uDj16tVLTzzxhOlYADQPiRy2ER8fr8bGRu/njRs3qrS0VBs2bNDatWvV1NSkYcOGKSkpSW+++abefvttJSYmavjw4d7jHnzwQS1ZskTPPvus3nrrLR08eFCrVq36yetee+21+vOf/6wFCxZo586deuqpp5SYmKiMjAy99NJLkqTS0lLt27dPjz76qCSpsLBQS5cu1ZNPPql//OMfmjZtmq655hoVFxdLOvoLx5gxYzRy5EiVlJTo+uuv18yZM03/M0lKStKSJUv0ySef6NFHH9XTTz+thx9+2GefsrIyPf/881qzZo3WrVun999/XzfffLP3+2XLlmnOnDmaP3++du7cqXvvvVezZ8/Wc889ZzoeAM1gABEoLy/PGDVqlGEYhuHxeIwNGzYYTqfTmD59uvf71NRUo6GhwXvMn/70J6Nnz56Gx+PxjjU0NBjx8fHG+vXrDcMwjM6dOxv333+/9/umpiajS5cu3msZhmFceOGFxq233moYhmGUlpYakowNGzacMM433njDkGR8++233rH6+nojISHB2LJli8++EydONK666irDMAxj1qxZRp8+fXy+nzFjxnHn+jFJxqpVq076/QMPPGAMGDDA+/nOO+80oqOjjT179njHXn31VSMqKsrYt2+fYRiGcfrppxvLly/3Oc/dd99t5OTkGIZhGLt27TIkGe+///5Jrwug+ZgjR8Rau3atEhMT1dTUJI/Ho6uvvlp33XWX9/t+/fr5zIt/8MEHKisrU1JSks956uvrVV5erurqau3bt8/nHewxMTE6++yzj2uvH1NSUqLo6GhdeOGFfsddVlam7777TpdcconPeGNjo375y19Kknbu3Hncu+BzcnL8vsYxK1eu1IIFC1ReXq7a2lodOXJELpfLZ5+uXbvq1FNP9bmOx+NRaWmpkpKSVF5erokTJ2rSpEnefY4cOaLk5GTT8QAwj0SOiDVkyBAtXLhQsbGxSk9PV0yM71/3tm3b+nyura3VgAEDtGzZsuPOdcoppzQrhvj4eNPH1NbWSpL+9re/+SRQ6ei8f6Bs3bpV48aN09y5czVs2DAlJydrxYoVevDBB03H+vTTTx/3i0V0dHTAYgVwciRyRKy2bdsqKyvL7/3POussrVy5Up06dTquKj2mc+fOeueddzRo0CBJRyvPHTt26Kyzzjrh/v369ZPH41FxcbFyc3OP+/5YR8DtdnvH+vTpI6fTqd27d5+0ku/du7d34d4x27Zt+/kf8v/YsmWLMjMz9dvf/tY79uWXXx633+7du7V3716lp6d7rxMVFaWePXsqNTVV6enp+vzzzzVu3DhT1wcQGCx2A34wbtw4dezYUaNGjdKbb76pXbt2adOmTbrlllu0Z88eSdKtt96q++67T6tXr9ann36qm2+++SfvAT/ttNOUl5en6667TqtXr/ae8/nnn5ckZWZmyuFwaO3atfr6669VW1urpKQkTZ8+XdOmTdNzzz2n8vJyvffee3rssce8C8huvPFGffbZZ7r99ttVWlqq5cuXa8mSJaZ+3h49emj37t1asWKFysvLtWDBghMu3IuLi1NeXp4++OADvfnmm7rlllt0xRVXKC0tTZI0d+5cFRYWasGCBfrnP/+pjz76SIsXL9ZDDz1kKh4AzUMiB36QkJCgzZs3q2vXrhozZox69+6tiRMnqr6+3luh33bbbfrP//xP5eXlKScnR0lJSbr88st/8rwLFy7Ur3/9a918883q1auXJk2apLq6OknSqaeeqrlz52rmzJlKTU3V5MmTJUl33323Zs+ercLCQvXu3VvDhw/X3/72N3Xr1k3S0Xnrl156SatXr1b//v315JNP6t577zX181522WWaNm2aJk+erDPPPFNbtmzR7Nmzj9svKytLY8aM0aWXXqqhQ4cqOzvb5/ay66+/Xs8884wWL16sfv366cILL9SSJUu8sQJoWQ7jZKt0AABAyKMiBwAgjJHIAQAIYyRyAADCGIkcAIAwRiIHACCMkcgBAAhjJHIAAMIYiRwAgDBGIgcAIIyRyAEACGMkcgAAwtj/B0pjglmCHd1wAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_true, pred_cat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "# TP | FN\n",
    "#--------\n",
    "# FP | TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_mod = confusion_matrix(test_true_mod, pred_cat_mod)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_mod)\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bestimmen Sie die Konfusionsmatrix und die Accuracy sowie für beide Klassen Precision, Recall und F1-Score. \n",
    "# Accuracy\n",
    "# True Tech + True NonTech / alles\n",
    "acc = (cm[0][0] + cm[1][1])/sum(sum(cm))\n",
    "\n",
    "# Tech\n",
    "    # Precision: True Tech / (True Tech + False Tech)\n",
    "prec_tech = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "    # Recall: True Tech / (True Tech + Flase NonTech)\n",
    "recall_tech = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_tech = 2*((prec_tech*recall_tech)/(prec_tech + recall_tech))\n",
    "\n",
    "# NonTech\n",
    "    # Precision: True NonTech / (True NonTech + False NonTech)\n",
    "prec_nonTech = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "    # Recall: True NonTech / (True NonTech + False Tech)\n",
    "recall_nonTech = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_nonTech = 2*((prec_nonTech*recall_nonTech)/(prec_nonTech + recall_nonTech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8588235294117647\n",
      "--------Tech---------\n",
      "Precision: 0.8113207547169812\n",
      "Recall: 0.9555555555555556\n",
      "F1-Score: 0.8775510204081634\n",
      "-------NonTech-------\n",
      "Precision: 0.9375\n",
      "Recall: 0.75\n",
      "F1-Score: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc}\")\n",
    "print(\"--------Tech---------\")\n",
    "print(f\"Precision: {prec_tech}\")\n",
    "print(f\"Recall: {recall_tech}\")\n",
    "print(f\"F1-Score: {f1_tech}\")\n",
    "print(\"-------NonTech-------\")\n",
    "print(f\"Precision: {prec_nonTech}\")\n",
    "print(f\"Recall: {recall_nonTech}\")\n",
    "print(f\"F1-Score: {f1_nonTech}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Diskutieren Sie das Ergebnis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trotz der Vernachlässigung der Semantik im Dokument ergibt sich eine Accuracy von 71,76%\n",
    "* Die Precision ist für nonTech Artikel besser als für Tech, der Classifier ist bei non Tech Artikel zuverlässiger\n",
    "* Der Recall für Tech ist besser als für nonTech, Tech Artikel werden öfter erkannt als nonTech Artikel\n",
    "* Der F1-Score ist bei Kategorie Tech höher als bei nonTech. Der Classifier ist besser angepasst auf Tech Artikel\n",
    "* Die Trainings Daten habe 160 Tech Dokumente und 105 nonTech Dokumente, somit ist der Classifier besser auf Tech Dokumente trainiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wie könnte die Klassifikationsgüte durch Modifikation der *getwords()*-Methode verbessert werden? Implementieren Sie diesen Ansatz und vergleichen Sie das Ergebnis mit dem des ersten Ansatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "# True Tech + True NonTech / alles\n",
    "acc_mod = (cm_mod[0][0] + cm_mod[1][1])/sum(sum(cm_mod))\n",
    "\n",
    "# Tech\n",
    "    # Precision: True Tech / (True Tech + False Tech)\n",
    "prec_tech_mod = cm_mod[0][0] / (cm_mod[0][0] + cm_mod[1][0])\n",
    "    # Recall: True Tech / (True Tech + Flase NonTech)\n",
    "recall_tech_mod = cm_mod[0][0] / (cm_mod[0][0] + cm_mod[0][1])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_tech_mod = 2*((prec_tech_mod*recall_tech_mod)/(prec_tech_mod + recall_tech_mod))\n",
    "\n",
    "# NonTech\n",
    "    # Precision: True NonTech / (True NonTech + False NonTech)\n",
    "prec_nonTech_mod = cm_mod[1][1] / (cm_mod[1][1] + cm_mod[0][1])\n",
    "    # Recall: True NonTech / (True NonTech + False Tech)\n",
    "recall_nonTech_mod = cm_mod[1][1] / (cm_mod[1][1] + cm_mod[1][0])\n",
    "    # F1-Score: 2* Precision * Recall / (Precision + Recall)\n",
    "f1_nonTech_mod = 2*((prec_nonTech_mod*recall_nonTech_mod)/(prec_nonTech_mod + recall_nonTech_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.788235294117647\n",
      "--------Tech---------\n",
      "Precision: 0.7288135593220338\n",
      "Recall: 0.9555555555555556\n",
      "F1-Score: 0.8269230769230769\n",
      "-------NonTech-------\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.6\n",
      "F1-Score: 0.7272727272727274\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {acc_mod}\")\n",
    "print(\"--------Tech---------\")\n",
    "print(f\"Precision: {prec_tech_mod}\")\n",
    "print(f\"Recall: {recall_tech_mod}\")\n",
    "print(f\"F1-Score: {f1_tech_mod}\")\n",
    "print(\"-------NonTech-------\")\n",
    "print(f\"Precision: {prec_nonTech_mod}\")\n",
    "print(f\"Recall: {recall_nonTech_mod}\")\n",
    "print(f\"F1-Score: {f1_nonTech_mod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsere Modefikation:\n",
    "getwordsmodified() zählt wie oft ein Wort in eine Artikel vorkommt und diese Zusatzinformation wird auch beim trainieren verwendet.\n",
    "Somit werden die Wörte nach Häufigkeit gewichtet.\n",
    "\n",
    "Durch unsere Modifikationen hat sich die Accuracy von 71% auf 75% verbessert (schwankt je nach Testdaten).\n",
    "Die Precision Werte sind bei beiden Kategorien gestiegen, der Wert bleibt jedoch höher bei der Kategorie nonTech.\n",
    "Die Recall Werte sind auch gestiegen, und auch hier bleibt der Wert für die Kategorie Tech höher (ähnlich wie bei nicht modifizierten).\n",
    "Der F1-Score erhöht sich auch bei beiden Kategorien, ist bei Tech aber höher als bei nonTech."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMaPR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
