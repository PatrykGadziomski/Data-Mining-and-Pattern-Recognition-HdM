1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training f칲r die sp칛tere Klassifikation abgespeichert werden?

```
Der Naive-Bayes Classifier wird 칲berwacht trainiert. Dabei wird ein Classifier mit den Wahrscheinlichkeiten traineirt, das ein wort w in einem Dokument der Klasse C_j vorkommt.

Die Variables cc und fc m칲ssen abgespeichert werden
- cc(cat): Anzahlder Trainingsdokumente der Kategorie cat
- fc(w,cat): Anzahl der Traiingsdokumente der Kategorie cat in denen das Wort w vorkommt
```

2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?

```
Mit Hilfe der posteriori Wahrschenlichkeit.

Diese wird mit der Likelihood-Funktion, Evidenz und der a-priori Wahrscheinlichkeiten berechnet.
```

3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tats칛chlich gegeben?

```
Annahme: Alle Eingabevektoren sind unabh칛ngig voneinander.
- Nein, da W칬rter in Dokumenten voneinander abh칛ngig sind.
```

4. Betrachten Sie die Formeln f칲r die Berechnung von 洧녞(洧냨|洧냥) und 洧녞(洧냣|洧냥). Welches Problem stellt sich ein, wenn in der Menge 洧녥(洧냥) ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie 洧냨 vorkommt und ein anderes Wort aus 洧녥(洧냥) nicht in den Trainingsdaten der Kategorie 洧냣 enthalten ist? Wie k칬nnte dieses Problem gel칬st werden?
![[Pasted image 20250114215732.png]]

```
P(w|G) bzw. P(w|B) sind 0 wenn w nich in G oder B ist, somit w칲rde auch das Produkt in P(G|D) bzw. P(B|D) gleich 0 sein. Dadurch sind dann auch P(G|D) bzw. P(B|D) gleich 0 wodurch D mit einer Wahrscheinlichkeit von 0 in B bzw. G ist. Das Problem k칬nnte gel칬st werden wenn man eine Standard wert einf칲hrt (zb. 0.1), damit nicht durch ein einzelens Wort in einem Dokument D, das nicht in den Trainingsdaten ist, ein Dokument nicht zugewiesen werden kann.
```

5. Wie k칬nnte die Klassifikationsg칲te durch Modifikation der `getwords()`\-Methode verbessert werden?
![[Pasted image 20250114215929.png]]

```
Eine denkbare Modifikation w칛re das Z칛hzlen: Wie oft ein Wort in eine Artikel vorkommt. Diese Zusatzinformation wird auch beim trainieren verwendet.

Somit werden die W칬rte nach H칛ufigkeit gewichtet.
```

6. F칲r einen Beispielsatz erhalten Sie die bedingten sowie die a-priori Wahrscheinlichkeiten. Berechnen Sie f칲r die gegebenen Wahrscheinlichkeiten die dazu geh칬rige Klasse?
![[Pasted image 20250114220243.png]]

```
Bad:  0.3 * 0.5 * 0.167 * 0.5 = 0.0125
Good: 0.7 * 0.167 * 0.5 * 0.5 = 0.029
```

7. Gegeben ist ein Bild einer Confusion Matrix. Berechnen Sie f칲r die gegebenen Werte die Accuracy (Recall, Precision). Schreiben Sie daf칲r erst die Formel auf und berechnen Sie diese dann.
![[Pasted image 20250114220623.png]]

```
Accuracy = TP+TN/TP+TN+FP+FN
         = 2+5/2+5+1+2 = 7/10 = 0.7

Precision = Class 1: TP/TP+FP; Class 2: TN/TN+FN
		  = Class 1: 2/2+1 = 2/3 ; Clas 2: 5/5+2 = 5/7

Recall = Class 1: TN/TN+FN ; Class 2: TN/TN+FP
	   = Class 1: 2/2+2 = 2 ; Class 2: 5/5+1 = 5/6
```

8. Beschreiben Sie in Worten was die Accuracy-Metrik (oder Recall und Precision) aussagt bzw. wie diese zu interpretieren ist?

```
Accuracy: Gibt den Anteil der korrekt klassifizierten datenpunkten an allen Datenpunkten an
- 100% = Alle Datenpunkte wurden richtig erkannt
- Funktioniert gut, wenn die Daten gleich verteilt sind

Precision: Misst wie viele der als positiv vorhergesagten Datenpunkte, tats칛chlich zur positiven Klassen geh칬ren
- Hohe Precision: Das Modell erzeugt kaum falsche Alarme
- Wichtig bei Genauigkeit der positiven Vorhersagen

Recall: Misst wie viele der tats칛chlichen positiven Datenpunkte korrelt als positiv vorhergesagt wurden
- Hoher Recall: Wenig positive Datenpunkte werden 칲bersehen
- Wichtig wenn alle positiven F칛lle erkannt werden sollen
```
